<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Taeyoon Kim">
<meta name="dcterms.date" content="2025-01-26">

<title>실습으로 배우는 대규모 언어 모델 – tomorrow-lab</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../.././static/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-3fdf7944b86790f1e71269a5b1fdffff.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-37f23b2833e9dfe84538c61756570b4f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-3fdf7944b86790f1e71269a5b1fdffff.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1596b96f4e3abbbc8f358abcb637f027.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-05bb4f325e51c109a15b3685f9b28ec8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-1596b96f4e3abbbc8f358abcb637f027.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-31EWCYNR0V"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-31EWCYNR0V', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<meta name="google-site-verification" content="z2S1Xqj9hfJiC31aNGCnOA1gYpL_8MoZpPI2avrWMvg">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="실습으로 배우는 대규모 언어 모델 – tomorrow-lab">
<meta property="og:description" content="The future of scientific discovery lies at the convergence of computational power and biological complexity. Our mission is to provide a platform where enthusiasts, researchers, and professionals can learn about and contribute to the rapidly evolving fields of bioinformatics, computational biology, and systems biology.">
<meta property="og:image" content="https://tomorrow-lab.github.io/posts/ipynb/LLM_HansOnLLM_files/figure-html/cell-7-output-2.png">
<meta property="og:site_name" content="tomorrow-lab">
<meta property="og:image:height" content="389">
<meta property="og:image:width" content="515">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../.././static/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">tomorrow-lab</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://partrita.github.io"> <i class="bi bi-exclamation-triangle" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/partrita"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<div style="margin-top: 30px; margin-bottom: 20px;">
    <a href="https://substack.com/@tomorrowlab">
        <img alt="Static Badge" src="https://img.shields.io/badge/EHOTTL%40substack_-FF6719?link=https%3A%2F%2Fsubstack.com%2F%40tomorrowlab">
    </a>
    <a href="https://pixi.sh">
        <img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/prefix-dev/pixi/main/assets/badge/v0.json" alt="Pixi Badge">
    </a>
    <!-- <script async src="https://eocampaign1.com/form/2616a818-1ef8-11ef-b372-4587d096212f.js" data-form="2616a818-1ef8-11ef-b372-4587d096212f"></script> -->
</div>

</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#대규모-언어-모델의-이해" id="toc-대규모-언어-모델의-이해" class="nav-link active" data-scroll-target="#대규모-언어-모델의-이해"><span class="header-section-number">1</span> 대규모 언어 모델의 이해</a>
  <ul class="collapse">
  <li><a href="#tokens-and-embedding" id="toc-tokens-and-embedding" class="nav-link" data-scroll-target="#tokens-and-embedding"><span class="header-section-number">1.1</span> Tokens and Embedding</a></li>
  <li><a href="#inside-of-llm" id="toc-inside-of-llm" class="nav-link" data-scroll-target="#inside-of-llm"><span class="header-section-number">1.2</span> Inside of LLM</a>
  <ul class="collapse">
  <li><a href="#최근-트랜스포머-블록의-발전" id="toc-최근-트랜스포머-블록의-발전" class="nav-link" data-scroll-target="#최근-트랜스포머-블록의-발전"><span class="header-section-number">1.2.1</span> 최근 트랜스포머 블록의 발전</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#사전-학습된-llm-사용" id="toc-사전-학습된-llm-사용" class="nav-link" data-scroll-target="#사전-학습된-llm-사용"><span class="header-section-number">2</span> 사전 학습된 LLM 사용</a>
  <ul class="collapse">
  <li><a href="#텍스트-분류" id="toc-텍스트-분류" class="nav-link" data-scroll-target="#텍스트-분류"><span class="header-section-number">2.1</span> 텍스트 분류</a>
  <ul class="collapse">
  <li><a href="#텍스트-감정-분석-with-representation-model" id="toc-텍스트-감정-분석-with-representation-model" class="nav-link" data-scroll-target="#텍스트-감정-분석-with-representation-model"><span class="header-section-number">2.1.1</span> 텍스트 감정 분석 with Representation model</a></li>
  <li><a href="#텍스트-감정-분석-with-generative-model" id="toc-텍스트-감정-분석-with-generative-model" class="nav-link" data-scroll-target="#텍스트-감정-분석-with-generative-model"><span class="header-section-number">2.1.2</span> 텍스트 감정 분석 with Generative model</a></li>
  </ul></li>
  <li><a href="#텍스트-클러스터링과-토픽-클러스터링" id="toc-텍스트-클러스터링과-토픽-클러스터링" class="nav-link" data-scroll-target="#텍스트-클러스터링과-토픽-클러스터링"><span class="header-section-number">2.2</span> 텍스트 클러스터링과 토픽 클러스터링</a>
  <ul class="collapse">
  <li><a href="#bertopic-모듈식-토픽-모델링-프레임워크" id="toc-bertopic-모듈식-토픽-모델링-프레임워크" class="nav-link" data-scroll-target="#bertopic-모듈식-토픽-모델링-프레임워크"><span class="header-section-number">2.2.1</span> BERTopic: 모듈식 토픽 모델링 프레임워크</a></li>
  </ul></li>
  <li><a href="#프롬프트-엔지니어링" id="toc-프롬프트-엔지니어링" class="nav-link" data-scroll-target="#프롬프트-엔지니어링"><span class="header-section-number">2.3</span> 프롬프트 엔지니어링</a>
  <ul class="collapse">
  <li><a href="#모델-출력-제어" id="toc-모델-출력-제어" class="nav-link" data-scroll-target="#모델-출력-제어"><span class="header-section-number">2.3.1</span> 모델 출력 제어</a></li>
  <li><a href="#고급-프롬프트-엔지니어링" id="toc-고급-프롬프트-엔지니어링" class="nav-link" data-scroll-target="#고급-프롬프트-엔지니어링"><span class="header-section-number">2.3.2</span> 고급 프롬프트 엔지니어링</a></li>
  <li><a href="#복잡한-프롬프트" id="toc-복잡한-프롬프트" class="nav-link" data-scroll-target="#복잡한-프롬프트"><span class="header-section-number">2.3.3</span> 복잡한 프롬프트</a></li>
  <li><a href="#문맥-내-학습-예시-제공" id="toc-문맥-내-학습-예시-제공" class="nav-link" data-scroll-target="#문맥-내-학습-예시-제공"><span class="header-section-number">2.3.4</span> 문맥 내 학습: 예시 제공</a></li>
  <li><a href="#chain-prompting-문제를-나누어-해결하기" id="toc-chain-prompting-문제를-나누어-해결하기" class="nav-link" data-scroll-target="#chain-prompting-문제를-나누어-해결하기"><span class="header-section-number">2.3.5</span> Chain Prompting: 문제를 나누어 해결하기</a></li>
  <li><a href="#생성형-모델을-이용한-추론" id="toc-생성형-모델을-이용한-추론" class="nav-link" data-scroll-target="#생성형-모델을-이용한-추론"><span class="header-section-number">2.3.6</span> 생성형 모델을 이용한 추론</a></li>
  <li><a href="#chain-of-thought-답변-전에-생각하기" id="toc-chain-of-thought-답변-전에-생각하기" class="nav-link" data-scroll-target="#chain-of-thought-답변-전에-생각하기"><span class="header-section-number">2.3.7</span> Chain-of-Thought: 답변 전에 생각하기</a></li>
  <li><a href="#제로샷-chain-of-thought" id="toc-제로샷-chain-of-thought" class="nav-link" data-scroll-target="#제로샷-chain-of-thought"><span class="header-section-number">2.3.8</span> 제로샷 Chain-of-Thought</a></li>
  <li><a href="#tree-of-thought-중간-단계-탐색하기" id="toc-tree-of-thought-중간-단계-탐색하기" class="nav-link" data-scroll-target="#tree-of-thought-중간-단계-탐색하기"><span class="header-section-number">2.3.9</span> Tree-of-Thought: 중간 단계 탐색하기</a></li>
  </ul></li>
  <li><a href="#의미론적-검색-및-검색-증강-생성" id="toc-의미론적-검색-및-검색-증강-생성" class="nav-link" data-scroll-target="#의미론적-검색-및-검색-증강-생성"><span class="header-section-number">2.4</span> 의미론적 검색 및 검색 증강 생성</a>
  <ul class="collapse">
  <li><a href="#밀집-검색-dense-retrieval" id="toc-밀집-검색-dense-retrieval" class="nav-link" data-scroll-target="#밀집-검색-dense-retrieval"><span class="header-section-number">2.4.1</span> 밀집 검색 (Dense Retrieval)</a></li>
  <li><a href="#재순위화-예시" id="toc-재순위화-예시" class="nav-link" data-scroll-target="#재순위화-예시"><span class="header-section-number">2.4.2</span> 재순위화 예시</a></li>
  <li><a href="#rag검색-증강-생성" id="toc-rag검색-증강-생성" class="nav-link" data-scroll-target="#rag검색-증강-생성"><span class="header-section-number">2.4.3</span> RAG(검색 증강 생성)</a></li>
  </ul></li>
  <li><a href="#멀티모달-llm" id="toc-멀티모달-llm" class="nav-link" data-scroll-target="#멀티모달-llm"><span class="header-section-number">2.5</span> 멀티모달 LLM</a>
  <ul class="collapse">
  <li><a href="#clip텍스트와-이미지-연결" id="toc-clip텍스트와-이미지-연결" class="nav-link" data-scroll-target="#clip텍스트와-이미지-연결"><span class="header-section-number">2.5.1</span> CLIP(텍스트와 이미지 연결)</a></li>
  <li><a href="#blip-2양식-간-격차-해소" id="toc-blip-2양식-간-격차-해소" class="nav-link" data-scroll-target="#blip-2양식-간-격차-해소"><span class="header-section-number">2.5.2</span> BLIP-2(양식 간 격차 해소)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#언어-모델-훈련-및-미세-조정" id="toc-언어-모델-훈련-및-미세-조정" class="nav-link" data-scroll-target="#언어-모델-훈련-및-미세-조정"><span class="header-section-number">3</span> 언어 모델 훈련 및 미세 조정</a>
  <ul class="collapse">
  <li><a href="#텍스트-임베딩-모델-생성" id="toc-텍스트-임베딩-모델-생성" class="nav-link" data-scroll-target="#텍스트-임베딩-모델-생성"><span class="header-section-number">3.1</span> 텍스트 임베딩 모델 생성</a>
  <ul class="collapse">
  <li><a href="#대조-생성generating-contrastive-예제" id="toc-대조-생성generating-contrastive-예제" class="nav-link" data-scroll-target="#대조-생성generating-contrastive-예제"><span class="header-section-number">3.1.1</span> 대조 생성(Generating Contrastive) 예제</a></li>
  <li><a href="#임베딩-모델의-미세-조정" id="toc-임베딩-모델의-미세-조정" class="nav-link" data-scroll-target="#임베딩-모델의-미세-조정"><span class="header-section-number">3.1.2</span> 임베딩 모델의 미세 조정</a></li>
  <li><a href="#비지도-학습" id="toc-비지도-학습" class="nav-link" data-scroll-target="#비지도-학습"><span class="header-section-number">3.1.3</span> 비지도 학습</a></li>
  </ul></li>
  <li><a href="#분류를-위한-표현-모델-미세-조정" id="toc-분류를-위한-표현-모델-미세-조정" class="nav-link" data-scroll-target="#분류를-위한-표현-모델-미세-조정"><span class="header-section-number">3.2</span> 분류를 위한 표현 모델 미세 조정</a>
  <ul class="collapse">
  <li><a href="#지도-학습-분류" id="toc-지도-학습-분류" class="nav-link" data-scroll-target="#지도-학습-분류"><span class="header-section-number">3.2.1</span> 지도 학습 분류</a></li>
  <li><a href="#적은-샷few-shot-분류" id="toc-적은-샷few-shot-분류" class="nav-link" data-scroll-target="#적은-샷few-shot-분류"><span class="header-section-number">3.2.2</span> 적은 샷(Few shot) 분류</a></li>
  </ul></li>
  <li><a href="#생성-모델-미세-조정" id="toc-생성-모델-미세-조정" class="nav-link" data-scroll-target="#생성-모델-미세-조정"><span class="header-section-number">3.3</span> 생성 모델 미세 조정</a>
  <ul class="collapse">
  <li><a href="#지도-학습-미세-조정-sft" id="toc-지도-학습-미세-조정-sft" class="nav-link" data-scroll-target="#지도-학습-미세-조정-sft"><span class="header-section-number">3.3.1</span> 지도 학습 미세 조정 (SFT)</a></li>
  <li><a href="#생성-모델-평가" id="toc-생성-모델-평가" class="nav-link" data-scroll-target="#생성-모델-평가"><span class="header-section-number">3.3.2</span> 생성 모델 평가</a></li>
  <li><a href="#선호도-튜닝-ppodpo" id="toc-선호도-튜닝-ppodpo" class="nav-link" data-scroll-target="#선호도-튜닝-ppodpo"><span class="header-section-number">3.3.3</span> 선호도 튜닝 (PPO/DPO)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#마치며" id="toc-마치며" class="nav-link" data-scroll-target="#마치며"><span class="header-section-number">4</span> 마치며</a></li>
  <li><a href="#참고-자료" id="toc-참고-자료" class="nav-link" data-scroll-target="#참고-자료"><span class="header-section-number">5</span> 참고 자료</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">실습으로 배우는 대규모 언어 모델</h1>
  <div class="quarto-categories">
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">Machine Learning</div>
    <div class="quarto-category">Python</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Taeyoon Kim </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 26, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">May 31, 2025</p>
    </div>
  </div>
    
  </div>
  


</header>


<p>최근 출간된 책 Hands-On Large Language Models (Jay Alammar, Maarten Grootendorst 저, 2024)을 읽고 그 내용을 정리해보려고 합니다. 이 책은 급속도로 발전하고 있는 대규모 언어 모델(Large Language Models, LLMs)의 이론을 쉽게 풀어내며 동시에 실습을 통해 독자들이 직접 경험할 수 있도록 구성했습니다. LLM의 전반적인 내용을 다루고 있어 AI와 자연어 처리에 관심 있는 분들에게 훌륭한 가이드가 될 것 같습니다. 이번 포스팅에서는 이 책의 내용 중 쓸만한 코드와 짧은 설명을 공유하려고 합니다.</p>
<section id="대규모-언어-모델의-이해" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 대규모 언어 모델의 이해</h1>
<section id="tokens-and-embedding" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="tokens-and-embedding"><span class="header-section-number">1.1</span> Tokens and Embedding</h2>
<p>토크나이저는 어떻게 텍스트를 자르는가? 3가지 중요 팩터: 1. 어휘 크기 (Vocabulary size) 2. 미등록 단어 (Out-of-vocabulary words) 처리 3. 언어의 특성 (Language characteristics)</p>
<p>토크나이저 분류</p>
<ol type="1">
<li>Word token: 공백이나 구두점을 기준으로 단어 단위로 분리</li>
<li>Subword token: 자주 사용되는 단어는 그대로 두고, 드문 단어는 더 작은 단위로 분리 (예: WordPiece, BPE)</li>
<li>Character token: 개별 문자 단위로 분리</li>
<li>Byte token: 바이트 단위로 분리, 모든 언어와 특수 문자 처리 가능</li>
</ol>
</section>
<section id="inside-of-llm" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="inside-of-llm"><span class="header-section-number">1.2</span> Inside of LLM</h2>
<p>LLM은 3개의 컴포넌트로 구성:</p>
<ul>
<li>Tokenizer: 입력 텍스트를 토큰으로 변환</li>
<li>Transformer: 토큰을 처리하고 문맥을 이해하는 핵심 아키텍처</li>
<li>LM head: Transformer의 출력을 받아 다음 토큰을 예측하는 층</li>
</ul>
<section id="최근-트랜스포머-블록의-발전" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="최근-트랜스포머-블록의-발전"><span class="header-section-number">1.2.1</span> 최근 트랜스포머 블록의 발전</h3>
<section id="rope" class="level4" data-number="1.2.1.1">
<h4 data-number="1.2.1.1" class="anchored" data-anchor-id="rope"><span class="header-section-number">1.2.1.1</span> RoPE</h4>
<p>RoPE는 다음과 같은 특징을 가집니다:</p>
<ul>
<li>상대적 위치 정보 인코딩: RoPE는 토큰 간의 상대적 위치 관계를 직접적으로 모델링합니다.</li>
<li>회전 행렬 사용: 위치 정보를 회전 행렬을 통해 인코딩하여 효율적으로 처리합니다.</li>
<li>길이 외삽(extrapolation) 능력: 학습 시 사용된 시퀀스 길이보다 긴 시퀀스에 대해서도 잘 작동합니다.</li>
<li>계산 효율성: 기존 위치 임베딩 방식에 비해 계산 효율성이 높습니다.</li>
<li>성능 향상: 특히 장문 텍스트 처리에서 성능 향상을 보입니다.</li>
</ul>
<p>RoPE는 GPT-3, PaLM, LLaMA 등 최신 대규모 언어 모델에서 널리 사용되고 있으며, 특히 긴 문맥을 다루는 데 효과적입니다.</p>
</section>
</section>
</section>
</section>
<section id="사전-학습된-llm-사용" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 사전 학습된 LLM 사용</h1>
<section id="텍스트-분류" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="텍스트-분류"><span class="header-section-number">2.1</span> 텍스트 분류</h2>
<p>자연어 처리에서 흔히 수행되는 작업 중 하나가 분류입니다. 이 작업의 목표는 입력된 텍스트에 레이블이나 클래스를 할당하도록 모델을 훈련시키는 것입니다. 텍스트 분류는 전 세계적으로 다양한 용도로 활용되고 있습니다. 감성 분석, 의도 파악, 개체 추출, 언어 감지 등이 그 예입니다.</p>
<p>대표적 언어 모델과 생성형 언어 모델이 분류 작업에 미치는 영향은 실로 막대합니다. 이러한 모델들은 텍스트 분류의 정확도와 효율성을 크게 향상시켰으며 더 복잡하고 미묘한 분류 작업을 가능하게 만들었습니다. 특히 사전 학습된 대규모 언어 모델(LLM)의 등장으로 텍스트 분류 작업의 성능이 비약적으로 발전했습니다.</p>
<section id="텍스트-감정-분석-with-representation-model" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="텍스트-감정-분석-with-representation-model"><span class="header-section-number">2.1.1</span> 텍스트 감정 분석 with Representation model</h3>
<p>텍스트 데이터를 가져와 텍스트의 감정 분석을 “cardiffnlp/twitter-roberta-base-sentiment-latest” 모델을 사용해 진행합니다. 이 모델은 RoBERTa 아키텍처를 기반으로 하며, 특히 트위터 데이터로 미세 조정되어 소셜 미디어 텍스트의 감정 분석에 최적화되어 있습니다.</p>
<div id="364a609e" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers.pipelines.pt_utils <span class="im">import</span> KeyDataset</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터셋 불러오기</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_dataset(<span class="st">"rotten_tomatoes"</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Hugging Face 모델</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>model_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">"cardiffnlp/twitter-roberta-base-sentiment-latest"</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델을 파이프라인에 로드</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(model<span class="op">=</span>model_name, tokenizer<span class="op">=</span>model_name, top_k<span class="op">=</span><span class="va">None</span>, device<span class="op">=</span><span class="st">"cuda:0"</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 추론 실행</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>y_pred: <span class="bu">list</span>[<span class="bu">int</span>] <span class="op">=</span> []</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> output <span class="kw">in</span> tqdm(pipe(KeyDataset(data[<span class="st">"test"</span>], <span class="st">"text"</span>)), total<span class="op">=</span><span class="bu">len</span>(data[<span class="st">"test"</span>])):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    negative_score <span class="op">=</span> output[<span class="dv">0</span>][<span class="st">"score"</span>]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    positive_score <span class="op">=</span> output[<span class="dv">2</span>][<span class="st">"score"</span>]</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    assignment <span class="op">=</span> np.argmax([negative_score, positive_score])</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    y_pred.append(assignment)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_performance(y_true: <span class="bu">list</span>[<span class="bu">int</span>], y_pred: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""분류 보고서 생성 및 출력"""</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    performance: <span class="bu">str</span> <span class="op">=</span> classification_report(y_true, y_pred, target_names<span class="op">=</span>[<span class="st">"부정적"</span>, <span class="st">"긍정적"</span>])</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(performance)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 성능 평가 실행</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>evaluate_performance(data[<span class="st">"test"</span>][<span class="st">"label"</span>], y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|█████████████████████████| 1066/1066 [00:02&lt;00:00, 459.29it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

         부정적       0.50      1.00      0.67       533
         긍정적       0.00      0.00      0.00       533

    accuracy                           0.50      1066
   macro avg       0.25      0.50      0.33      1066
weighted avg       0.25      0.50      0.33      1066
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
</section>
<section id="텍스트-감정-분석-with-generative-model" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="텍스트-감정-분석-with-generative-model"><span class="header-section-number">2.1.2</span> 텍스트 감정 분석 with Generative model</h3>
<p>생성형 모델을 사용한 텍스트 감정 분석은 기존의 분류 기반 접근 방식과는 다른 새로운 패러다임을 제시합니다. 이 방식은 기존 방법보다 더 정확하고 세밀한 결과를 제공할 수 있지만, 모델의 훈련과 계산 비용이 높다는 단점도 있습니다.</p>
<div id="2bf7aab2" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers.pipelines.pt_utils <span class="im">import</span> KeyDataset</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 영화 리뷰 데이터셋 로드</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_dataset(<span class="st">"rotten_tomatoes"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Hugging Face 모델</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>model_name: <span class="bu">str</span> <span class="op">=</span> <span class="st">"google/flan-t5-small"</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델을 파이프라인에 로드</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(<span class="st">"text2text-generation"</span>, model<span class="op">=</span>model_name, device<span class="op">=</span><span class="st">"cuda:0"</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터 준비</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Is the following sentence positive or negative? "</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.<span class="bu">map</span>(<span class="kw">lambda</span> example: {<span class="st">"t5"</span>: prompt <span class="op">+</span> example[<span class="st">"text"</span>]})</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 추론 실행</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> []</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> output <span class="kw">in</span> tqdm(pipe(KeyDataset(data[<span class="st">"test"</span>], <span class="st">"t5"</span>)), total<span class="op">=</span><span class="bu">len</span>(data[<span class="st">"test"</span>])):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> output[<span class="dv">0</span>][<span class="st">"generated_text"</span>]</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    y_pred.append(<span class="dv">0</span> <span class="cf">if</span> text <span class="op">==</span> <span class="st">"negative"</span> <span class="cf">else</span> <span class="dv">1</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_performance(y_true: <span class="bu">list</span>[<span class="bu">int</span>], y_pred: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""분류 보고서 생성 및 출력"""</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    performance: <span class="bu">str</span> <span class="op">=</span> classification_report(y_true, y_pred, target_names<span class="op">=</span>[<span class="st">"부정적"</span>, <span class="st">"긍정적"</span>])</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(performance)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 성능 평가 실행</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>evaluate_performance(data[<span class="st">"test"</span>][<span class="st">"label"</span>], y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|█████████████████████████| 1066/1066 [00:08&lt;00:00, 121.39it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

         부정적       0.83      0.85      0.84       533
         긍정적       0.85      0.83      0.84       533

    accuracy                           0.84      1066
   macro avg       0.84      0.84      0.84      1066
weighted avg       0.84      0.84      0.84      1066
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
</section>
</section>
<section id="텍스트-클러스터링과-토픽-클러스터링" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="텍스트-클러스터링과-토픽-클러스터링"><span class="header-section-number">2.2</span> 텍스트 클러스터링과 토픽 클러스터링</h2>
<p>텍스트 클러스터링과 토픽 모델링은 문서 컬렉션을 분석하는 두 가지 주요 접근 방식입니다. 텍스트 클러스터링은 유사한 문서들을 그룹화하여 컬렉션을 여러 클러스터로 나누는 것을 목표로 합니다. 일반적으로 각 문서는 하나의 클러스터에만 속하게 됩니다. 반면 토픽 모델링은 문서 컬렉션에 내재된 추상적인 ’토픽’들을 발견하는 것을 목표로 합니다.</p>
<section id="bertopic-모듈식-토픽-모델링-프레임워크" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="bertopic-모듈식-토픽-모델링-프레임워크"><span class="header-section-number">2.2.1</span> BERTopic: 모듈식 토픽 모델링 프레임워크</h3>
<p>BERTopic은 최신 자연어 처리 기술을 활용한 강력한 토픽 모델링 프레임워크입니다. BERTopic은 전통적인 토픽 모델링 기법인 LDA에 비해 더 정교한 결과를 제공할 수 있으며, 특히 짧은 텍스트나 특정 도메인의 텍스트에 대해 우수한 성능을 보입니다. 학술 연구, 소셜 미디어 분석, 고객 피드백 분석 등 다양한 분야에서 활용될 수 있으며, 대규모 문서 컬렉션에서 의미 있는 인사이트를 추출하는 데 유용합니다.</p>
<div id="fd0596bb-ba17-4a6c-88e4-66511a5005ac" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hdbscan <span class="im">import</span> HDBSCAN</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># huggingface에서 데이터 로드</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"effectiveML/ArXiv-10"</span>)[<span class="st">"train"</span>]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 메타데이터 추출</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>abstracts <span class="op">=</span> dataset[<span class="st">"abstract"</span>]</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>titles <span class="op">=</span> dataset[<span class="st">"title"</span>]</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 1단계</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 각 초록에 대한 임베딩 생성</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> SentenceTransformer(<span class="st">"thenlper/gte-small"</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> embedding_model.encode(abstracts, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 2단계</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 384차원의 입력 임베딩을 50차원으로 축소</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>umap_model <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">50</span>, min_dist<span class="op">=</span><span class="fl">0.0</span>, metric<span class="op">=</span><span class="st">"cosine"</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>reduced_embeddings <span class="op">=</span> umap_model.fit_transform(embeddings)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 3단계</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델을 학습하고 클러스터 추출</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>hdbscan_model <span class="op">=</span> HDBSCAN(</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    min_cluster_size<span class="op">=</span><span class="dv">50</span>, metric<span class="op">=</span><span class="st">"euclidean"</span>, cluster_selection_method<span class="op">=</span><span class="st">"eom"</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>).fit(reduced_embeddings)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> hdbscan_model.labels_</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 시각화를 위한 준비: 384차원 임베딩을 2차원으로 축소</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>reduced_embeddings <span class="op">=</span> umap.UMAP(</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    n_components<span class="op">=</span><span class="dv">2</span>, min_dist<span class="op">=</span><span class="fl">0.0</span>, metric<span class="op">=</span><span class="st">"cosine"</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>).fit_transform(embeddings)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터프레임 생성</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(reduced_embeddings, columns<span class="op">=</span>[<span class="st">"x"</span>, <span class="st">"y"</span>])</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"title"</span>] <span class="op">=</span> titles</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"cluster"</span>] <span class="op">=</span> [<span class="bu">str</span>(c) <span class="cf">for</span> c <span class="kw">in</span> clusters]</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 이상치와 비이상치(클러스터) 선택</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>clusters_df <span class="op">=</span> df.loc[df.cluster <span class="op">!=</span> <span class="st">"-1"</span>, :]</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>outliers_df <span class="op">=</span> df.loc[df.cluster <span class="op">==</span> <span class="st">"-1"</span>, :]</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a><span class="co"># 플랏 크기 지정</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>plt.scatter(</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>    outliers_df.x,</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    outliers_df.y,</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>    c<span class="op">=</span><span class="st">"grey"</span>,</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>plt.scatter(</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>    clusters_df.x,</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>    clusters_df.y,</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>    c<span class="op">=</span>clusters_df.cluster.astype(<span class="bu">int</span>),</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.15</span>,</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"viridis_r"</span>,</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8aa485e3e76f4041a1670e36d388227a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="LLM_HansOnLLM_files/figure-html/cell-7-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="LLM_HansOnLLM_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="99c52e97-c17f-4986-8832-e712a8dde976" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> copy <span class="im">import</span> deepcopy</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic <span class="im">import</span> BERTopic</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic.representation <span class="im">import</span> TextGeneration</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># BERTopic 모델 훈련</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>topic_model <span class="op">=</span> BERTopic(</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    embedding_model<span class="op">=</span>embedding_model,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    umap_model<span class="op">=</span>umap_model,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    hdbscan_model<span class="op">=</span>hdbscan_model,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>).fit(abstracts, embeddings)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 원본 표현 저장</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>original_topics <span class="op">=</span> deepcopy(topic_model.topic_representations_)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Flan-T5를 사용한 토픽 표현 업데이트</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> pipeline(<span class="st">"text2text-generation"</span>, model<span class="op">=</span><span class="st">"google/flan-t5-small"</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 프롬프트 정의</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"""I have a topic that contains the following documents:</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="st">[DOCUMENTS]</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="st">The topic is described by the following keywords: '[KEYWORDS]'.</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="st">Based on the documents and keywords, what is this topic about?"""</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>representation_model <span class="op">=</span> TextGeneration(</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    generator, prompt<span class="op">=</span>prompt, doc_length<span class="op">=</span><span class="dv">50</span>, tokenizer<span class="op">=</span><span class="st">"whitespace"</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>topic_model.update_topics(abstracts, representation_model<span class="op">=</span>representation_model)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 토픽 차이 표시 함수</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> topic_differences(model, original_topics, nr_topics<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""두 모델 간의 토픽 표현 차이를 보여줍니다"""</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Topic"</span>, <span class="st">"Original"</span>, <span class="st">"Updated"</span>])</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> topic <span class="kw">in</span> <span class="bu">range</span>(nr_topics):</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 모델별로 토픽당 상위 5개 단어 추출</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>        og_words <span class="op">=</span> <span class="st">" | "</span>.join(<span class="bu">list</span>(<span class="bu">zip</span>(<span class="op">*</span>original_topics[topic]))[<span class="dv">0</span>][:<span class="dv">5</span>])</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>        new_words <span class="op">=</span> <span class="st">" "</span>.join(<span class="bu">list</span>(<span class="bu">zip</span>(<span class="op">*</span>model.get_topic(topic)))[<span class="dv">0</span>][:<span class="dv">5</span>])</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>        df.loc[<span class="bu">len</span>(df)] <span class="op">=</span> [topic, og_words, new_words]</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a><span class="co"># 토픽 차이 출력</span></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(topic_differences(topic_model, original_topics))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2025-01-21 12:04:12,339 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm
2025-01-21 12:05:33,792 - BERTopic - Dimensionality - Completed ✓
2025-01-21 12:05:33,799 - BERTopic - Cluster - Start clustering the reduced embeddings
2025-01-21 12:05:37,721 - BERTopic - Cluster - Completed ✓
2025-01-21 12:05:37,728 - BERTopic - Representation - Extracting topics from clusters using representation models.
2025-01-21 12:05:41,069 - BERTopic - Representation - Completed ✓
100%|████████████████████████████| 205/205 [00:03&lt;00:00, 54.17it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>   Topic                                           Original  \
0      0                 mathbb | prove | mathcal | we | if   
1      1                      flow | fluid | the | of | and   
2      2  channel | wireless | communication | mimo | pr...   
3      3  quantum | entanglement | states | bell | measu...   
4      4  solar | plasma | magnetic | coronal | reconnec...   

                    Updated  
0                 Maths      
1              dynamics      
2            Networking      
3  Quantum entanglement      
4          Solar-energy      </code></pre>
</div>
</div>
<div id="a7548dcf-4f7a-46a2-84d4-5268d94714c8" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> topic_model.visualize_document_datamap(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    titles,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">""</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    topics<span class="op">=</span><span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">20</span>)),</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    reduced_embeddings<span class="op">=</span>reduced_embeddings,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    width<span class="op">=</span><span class="dv">600</span>,  <span class="co"># 7인치에 해당하는 픽셀 수 (100 픽셀/인치 기준)</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    height<span class="op">=</span><span class="dv">600</span>,  <span class="co"># 7인치에 해당하는 픽셀 수</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    label_font_size<span class="op">=</span><span class="dv">11</span>,  <span class="co"># 텍스트 크기 축소</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    label_wrap_width<span class="op">=</span><span class="dv">15</span>,  <span class="co"># 레이블 줄바꿈 너비 축소</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    use_medoids<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="LLM_HansOnLLM_files/figure-html/cell-9-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="LLM_HansOnLLM_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="프롬프트-엔지니어링" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="프롬프트-엔지니어링"><span class="header-section-number">2.3</span> 프롬프트 엔지니어링</h2>
<p>생성형 사전 학습 트랜스포머(GPT) 모델은 사용자가 제시한 프롬프트에 대응하여 텍스트를 생성하는 놀라운 능력을 갖추고 있습니다. 프롬프트 엔지니어링을 통해 이러한 프롬프트를 효과적으로 설계함으로써 생성되는 텍스트의 품질을 크게 향상시킬 수 있습니다.</p>
<p>이번에는 이러한 생성형 모델에 대해 더 자세히 살펴보고, 프롬프트 엔지니어링의 세계로 깊이 들어가 보겠습니다. 또한 생성형 모델을 이용한 추론, 검증, 그리고 모델 출력의 평가 방법까지 다루어 볼 것입니다.</p>
<p>프롬프트 엔지니어링은 단순히 질문을 던지는 것을 넘어서, 모델이 원하는 방식으로 응답하도록 유도하는 기술입니다. 이는 모델의 성능을 최적화하고, 특정 작업에 맞춤화된 결과를 얻는 데 핵심적인 역할을 합니다.</p>
<div id="45c9e1ee-edb4-458b-8044-f55b091b5843" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    AutoModelForCausalLM,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    logging,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    pipeline,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 사용할 모델 이름 지정</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"microsoft/Phi-3.5-mini-instruct"</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 로드 및 설정</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    model_name,</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"cuda"</span>,  <span class="co"># GPU 사용</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    torch_dtype<span class="op">=</span>torch.float16,  <span class="co"># 16비트 부동소수점 사용</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    trust_remote_code<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 토크나이저 로드</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 텍스트 생성 파이프라인 설정</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text-generation"</span>,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,  <span class="co"># 모델 지정</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,  <span class="co"># 토크나이저 지정</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    return_full_text<span class="op">=</span><span class="va">False</span>,  <span class="co"># 전체 텍스트 반환 안 함</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    max_new_tokens<span class="op">=</span><span class="dv">500</span>,  <span class="co"># 최대 새 토큰 수</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    do_sample<span class="op">=</span><span class="va">False</span>,  <span class="co"># 샘플링 사용 안 함</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 프롬프트 설정</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>messages <span class="op">=</span> [</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"직장동료에게 보내는 이메일의 짧은 인사말 3개만 적어줘."</span>,</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 생성</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> pipe(messages)</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 생성된 텍스트 출력</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.
Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0f8ef81a8c3a4e7d87938c67a78e69d9","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>You are not running the flash-attention implementation, expect numerical differences.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> 제목: 환영 인사드리기

안녕 친구,

안녕하세요! 이 이메일을 보내드리고 직장에 합류하게 되어 기쁩니다. 팀에서 함께 일하고 함께 성장하기를 기대합니다. 행운을 빌어요!

감사합니다,
[당신의 이름]</code></pre>
</div>
</div>
<section id="모델-출력-제어" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="모델-출력-제어"><span class="header-section-number">2.3.1</span> 모델 출력 제어</h3>
<p>모델 매개변수를 조정하여 원하는 종류의 출력을 제어할 수 있습니다. <strong>temperature</strong>와 <strong>top_p</strong> 매개변수는 출력의 무작위성을 제어합니다.</p>
<section id="temperature온도" class="level4" data-number="2.3.1.1">
<h4 data-number="2.3.1.1" class="anchored" data-anchor-id="temperature온도"><span class="header-section-number">2.3.1.1</span> Temperature(온도)</h4>
<p>Temperature는 생성된 텍스트의 무작위성 또는 창의성을 제어합니다. 이는 확률이 낮은 토큰을 선택할 가능성을 정의합니다. 기본 아이디어는 temperature가 0이면 항상 가장 가능성이 높은 단어를 선택하기 때문에 매번 동일한 응답을 생성한다는 것입니다.</p>
</section>
<section id="top_p" class="level4" data-number="2.3.1.2">
<h4 data-number="2.3.1.2" class="anchored" data-anchor-id="top_p"><span class="header-section-number">2.3.1.2</span> top_p</h4>
<p>top_p(핵 샘플링이라고도 함)는 LLM이 고려할 수 있는 토큰의 부분집합(핵)을 제어하는 샘플링 기법입니다. 누적 확률에 도달할 때까지 토큰을 고려합니다. top_p를 0.1로 설정하면 해당 값에 도달할 때까지 토큰을 고려합니다.</p>
<div id="670cdb65-796e-4639-a03b-878698da4168" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using a high temperature</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> pipe(messages, do_sample<span class="op">=</span><span class="va">True</span>, temperature<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 제목: 안녕하세요, [동료 이름]

안녕하세요! 저를 잘 기억해주시고, 전문적인 지원과 협력을 이어오시길 바랍니다.

감사드립니다!

[당신의 이름]</code></pre>
</div>
</div>
<div id="fb563e73-d63c-4ef9-bdd5-dd204642a5b5" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using a high top_p</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> pipe(messages, do_sample<span class="op">=</span><span class="va">True</span>, top_p<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 제목: 인사 릴렉센

---

1. 빠른 칭호와 행운을 바쳐:
   안녕하세요 [동료 이름],

   이 메시지를 전해드리며, 우리를 부러워하게 만드는 발신인 이 글을 통해 전하고자 합니다. 이 역할에서 네가 저녁부터 아침까지 우수하게 일하고 있다는 증거로 자리매김하는 것을 자랑스럽게 여깁니다.

2. 긍정적인 기여에 감사:
   네가 간략한 지원도 및 공유된 실력에 영향을 미친 프로젝트와 빈틈없는 팀플 작물에 큰 마스터피스를 제공해주셨습니다. 이 회사를 하나의 개인으로부터 더 강력하고 협력적인 집단으로 시간이 지나면서 지속적인 성장을 목격하고 있습니다.

3. 앞으로의 연결:
   이 인사의 마당에 더 나</code></pre>
</div>
</div>
</section>
</section>
<section id="고급-프롬프트-엔지니어링" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="고급-프롬프트-엔지니어링"><span class="header-section-number">2.3.2</span> 고급 프롬프트 엔지니어링</h3>
<p>좋은 프롬프트를 만드는 것은 간단해 보일 수 있습니다. 구체적인 질문을 하고, 정확하게 표현하며, 몇 가지 예시를 추가하면 끝난 것 같죠! 하지만 프롬프트 작성은 매우 빠르게 복잡해질 수 있으며, 그 결과 대규모 언어 모델(LLM)을 활용하는 데 있어 종종 과소평가되는 요소입니다. 여기서는 프롬프트를 구축하기 위한 여러 가지 고급 기법을 살펴보겠습니다.</p>
</section>
<section id="복잡한-프롬프트" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="복잡한-프롬프트"><span class="header-section-number">2.3.3</span> 복잡한 프롬프트</h3>
<p>이 복잡한 프롬프트는 프롬프트 작성의 모듈식 특성을 보여줍니다. 우리는 자유롭게 구성 요소를 추가하거나 제거할 수 있고 출력에 미치는 영향을 판단할 수 있습니다.</p>
<div id="e5ec1a0b-d299-4bdd-b63c-88b1855dacf9" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 프롬프트 구성 요소</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>persona <span class="op">=</span> <span class="st">"당신은 인공지능과 기계학습 분야의 전문가입니다. 복잡한 기술 문서를 쉽게 이해할 수 있는 요약으로 만드는 데 탁월합니다.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>instruction <span class="op">=</span> <span class="st">"제공된 기술 문서의 핵심 내용을 요약해주세요.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>context <span class="op">=</span> <span class="st">"요약은 개발자들이 문서의 가장 중요한 정보를 빠르게 파악할 수 있도록 핵심 포인트를 추출해야 합니다.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>data_format <span class="op">=</span> <span class="st">"주요 개념과 기술을 설명하는 글머리 기호 요약을 만드세요. 그 다음 주요 내용을 간결하게 요약하는 단락을 작성하세요.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>audience <span class="op">=</span> <span class="st">"이 요약은 최신 AI 개발 동향을 빠르게 파악해야 하는 바쁜 개발자들을 위한 것입니다.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>tone <span class="op">=</span> <span class="st">"전문적이고 명확한 톤을 사용해야 합니다.</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 아래 내용을 원하는 문장으로 변경했습니다.</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="st">머신러닝 모델의 성능을 향상시키는 방법 중 하나는 앙상블 학습입니다. 앙상블 학습은 여러 개의 모델을 조합하여 더 나은 예측 결과를 얻는 방법입니다.</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="st">주요 앙상블 기법으로는 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking)이 있습니다.</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="st">배깅은 동일한 알고리즘을 사용하지만 서로 다른 학습 데이터 부분집합으로 여러 모델을 학습시키는 방법입니다.</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="st">부스팅은 이전 모델의 오류를 보완하는 방향으로 순차적으로 모델을 학습시키는 방법입니다.</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="st">스태킹은 여러 모델의 예측 결과를 새로운 모델의 입력으로 사용하여 최종 예측을 수행하는 방법입니다.</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="st">이러한 앙상블 기법들은 단일 모델보다 일반적으로 더 높은 성능과 안정성을 제공합니다.</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="ss">f"요약할 텍스트: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 전체 프롬프트 - 생성된 출력에 미치는 영향을 보기 위해 부분을 제거하거나 추가할 수 있습니다</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> persona <span class="op">+</span> instruction <span class="op">+</span> context <span class="op">+</span> data_format <span class="op">+</span> audience <span class="op">+</span> tone <span class="op">+</span> data</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>messages <span class="op">=</span> [{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: query}]</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokenizer.apply_chat_template(messages, tokenize<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 생성</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(messages)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;|user|&gt;
당신은 인공지능과 기계학습 분야의 전문가입니다. 복잡한 기술 문서를 쉽게 이해할 수 있는 요약으로 만드는 데 탁월합니다.
제공된 기술 문서의 핵심 내용을 요약해주세요.
요약은 개발자들이 문서의 가장 중요한 정보를 빠르게 파악할 수 있도록 핵심 포인트를 추출해야 합니다.
주요 개념과 기술을 설명하는 글머리 기호 요약을 만드세요. 그 다음 주요 내용을 간결하게 요약하는 단락을 작성하세요.
이 요약은 최신 AI 개발 동향을 빠르게 파악해야 하는 바쁜 개발자들을 위한 것입니다.
전문적이고 명확한 톤을 사용해야 합니다.
요약할 텍스트: 
머신러닝 모델의 성능을 향상시키는 방법 중 하나는 앙상블 학습입니다. 앙상블 학습은 여러 개의 모델을 조합하여 더 나은 예측 결과를 얻는 방법입니다.
주요 앙상블 기법으로는 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking)이 있습니다.
배깅은 동일한 알고리즘을 사용하지만 서로 다른 학습 데이터 부분집합으로 여러 모델을 학습시키는 방법입니다.
부스팅은 이전 모델의 오류를 보완하는 방향으로 순차적으로 모델을 학습시키는 방법입니다.
스태킹은 여러 모델의 예측 결과를 새로운 모델의 입력으로 사용하여 최종 예측을 수행하는 방법입니다.
이러한 앙상블 기법들은 단일 모델보다 일반적으로 더 높은 성능과 안정성을 제공합니다.
&lt;|end|&gt;
&lt;|endoftext|&gt;
 **요약: 앙상블 학습을 통한 머신러닝 성능 향상**

*글머리기호 요약:*
- 앙상블 학습: 여러 모델의 조합
- 주요 기법: 배깅, 부스팅, 스태킹
- 성능 향상: 일반적으로 더 높고 안정적

*요약 단락:*
앙상블 학습은 머신러닝 모델의 성능을 향상시키기 위해 여러 개의 모델을 조합하는 기술입니다. 주요 앙상블 기법에는 배깅, 부스팅, 스태킹이 포함됩니다.

배깅은 동일한 알고리즘을 사용하면서 서로 다른 학습 데이터 부분집합으로 여러 모델을 학습시키는 방법입니다. 이 방법은 모델의 불필요한 동질성을 줄이고 오류를 완화하여 더 안정적인 예측을 제공합니다.

부스팅은 이전 모</code></pre>
</div>
</div>
</section>
<section id="문맥-내-학습-예시-제공" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="문맥-내-학습-예시-제공"><span class="header-section-number">2.3.4</span> 문맥 내 학습: 예시 제공</h3>
<p>우리는 LLM(대규모 언어 모델)에 우리가 정확히 달성하고자 하는 것의 예시를 제공할 수 있습니다. 이는 종종 문맥 내 학습이라고 불리며, 모델에 정확한 예시를 제공하는 방식입니다.</p>
<div id="9b3b3bf6-1bc6-4596-abb2-f2e71167e906" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 만들어낸 단어를 문장에서 사용하는 단일 예시 활용</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>one_shot_prompt <span class="op">=</span> [</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"'퀴블녹스'는 자유자재로 크기를 바꿀 수 있는 마법 생물입니다. '퀴블녹스'라는 단어를 사용한 문장의 예시는 다음과 같습니다:"</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"assistant"</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"여행을 갈 때 내 애완 퀴블녹스는 쥐만큼 작아져서 주머니에 쉽게 넣고 다닐 수 있어요."</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"'실드치다'는 어처구니 없는 상황이나 인물의 입장을 방어하는 것을 의미합니다. '실드치다'라는 단어를 사용한 문장의 예시는 다음과 같습니다:"</span>,</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokenizer.apply_chat_template(one_shot_prompt, tokenize<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 생성</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(one_shot_prompt)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;|user|&gt;
'퀴블녹스'는 자유자재로 크기를 바꿀 수 있는 마법 생물입니다. '퀴블녹스'라는 단어를 사용한 문장의 예시는 다음과 같습니다:&lt;|end|&gt;
&lt;|assistant|&gt;
여행을 갈 때 내 애완 퀴블녹스는 쥐만큼 작아져서 주머니에 쉽게 넣고 다닐 수 있어요.&lt;|end|&gt;
&lt;|user|&gt;
'줌블하다'는 비정통적이지만 효과적인 방식으로 문제를 해결하는 것을 의미합니다. '줌블하다'라는 단어를 사용한 문장의 예시는 다음과 같습니다:&lt;|end|&gt;
&lt;|endoftext|&gt;
 올해의 과제를 처리하는 데 어려움을 겪으며, 우리는 줌블하게 새로운 프로세스를 도입하여 효율성을 높이고 성공적으로 마무리했습니다.</code></pre>
</div>
</div>
</section>
<section id="chain-prompting-문제를-나누어-해결하기" class="level3" data-number="2.3.5">
<h3 data-number="2.3.5" class="anchored" data-anchor-id="chain-prompting-문제를-나누어-해결하기"><span class="header-section-number">2.3.5</span> Chain Prompting: 문제를 나누어 해결하기</h3>
<p>문제를 하나의 프롬프트 내에서 해결하는 대신, 여러 프롬프트 사이에서 나누어 해결할 수 있습니다. 본질적으로 이 방법은 한 프롬프트의 출력을 다음 프롬프트의 입력으로 사용하여 문제를 해결하는 연속적인 상호작용 체인을 만드는 것입니다. Chain Prompting은 특히 다단계 추론, 복잡한 분석, 또는 여러 도메인의 지식을 결합해야 하는 작업에서 효과적입니다.</p>
<div id="cbb696bc-ee32-4971-ac48-1359235664e8" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 스마트홈 기기의 이름과 슬로건 생성</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>product_prompt <span class="op">=</span> [{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"스마트홈 기기의 이름과 슬로건을 만들어주세요."</span>}]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(product_prompt)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>product_description <span class="op">=</span> outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>]</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(product_description)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 생성된 제품 이름과 슬로건을 바탕으로 짧은 판매 문구 생성</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>sales_prompt <span class="op">=</span> [</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="ss">f"다음 제품에 대한 매우 짧은 판매 문구를 생성해주세요: '</span><span class="sc">{</span>product_description<span class="sc">}</span><span class="ss">'"</span>,</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(sales_prompt)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>sales_pitch <span class="op">=</span> outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>]</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sales_pitch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 이름: "SmartHaven"

슬로건: "SmartHaven - 디지털 편안함, 현실 속 편안한 집."

SmartHaven는 스마트홈 기기의 편안함과 효율성을 실현하는 최첨단 기기로, 집의 모든 영역에서 디지털 혁신을 제공합니다. 이 기기는 생활의 질을 향상시키고, 집의 안전성을 강화하며, 사용자의 생활을 효율적이고 편안하게 만듭니다. SmartHaven의 디지털 편안함과 현실 속 편안한 집을 상징하는 슬로건은 이러한 기능을 강조하고, 소비자들이 스마트홈의 풍부한 가치를 느낄 수 있도록 합니다.
 "SmartHaven: 현실 속 편안한 집, 디지털 편안함을 누릴 순간."</code></pre>
</div>
</div>
</section>
<section id="생성형-모델을-이용한-추론" class="level3" data-number="2.3.6">
<h3 data-number="2.3.6" class="anchored" data-anchor-id="생성형-모델을-이용한-추론"><span class="header-section-number">2.3.6</span> 생성형 모델을 이용한 추론</h3>
<p>추론은 인간 지능의 핵심 요소이며 종종 추론과 유사해 보이는 LLM의 창발적 행동과 비교됩니다. 우리가 “유사해 보이는”이라고 강조하는 이유는 이 글을 쓰는 시점에서 이러한 모델들은 일반적으로 학습 데이터의 암기와 패턴 매칭을 통해 이러한 행동을 보여주는 것으로 여겨지기 때문입니다.</p>
</section>
<section id="chain-of-thought-답변-전에-생각하기" class="level3" data-number="2.3.7">
<h3 data-number="2.3.7" class="anchored" data-anchor-id="chain-of-thought-답변-전에-생각하기"><span class="header-section-number">2.3.7</span> Chain-of-Thought: 답변 전에 생각하기</h3>
<p>Chain-of-Thought(사고 연쇄)는 생성형 모델이 질문에 직접 답변하지 않고 먼저 “생각”하도록 하는 것을 목표로 합니다.Chain-of-Thought 방식은 특히 수학 문제 풀이, 논리 퍼즐, 복잡한 의사 결정 과정 등에서 효과적으로 사용될 수 있으며, 모델의 추론 능력을 향상시키는 데 도움이 됩니다.</p>
<div id="8087489e-d0ed-4fe7-b40c-f9bf529a1d50" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 명시적인 추론 없이 답변하기</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>standard_prompt <span class="op">=</span> [</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"민수는 색연필 12자루를 가지고 있었습니다. 새 색연필 세트를 받았는데, 그 세트에는 8자루가 들어있었습니다. 그런데 3자루를 동생에게 주었습니다. 민수는 지금 몇 자루의 색연필을 가지고 있나요?"</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"assistant"</span>, <span class="st">"content"</span>: <span class="st">"17"</span>},</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"학교 도서관에 책이 300권 있었습니다. 새로운 책 50권을 구입했고, 학생들이 25권을 빌려갔습니다. 지금 도서관에 있는 책은 몇 권인가요?"</span>,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 생성 모델 실행</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(standard_prompt)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 325권

이 문제를 해결하기 위해서는 다음 단계를 따릅니다:

1. 도서관에는 초기에 300권의 책이 있었습니다.
2. 새로운 책 50권을 도서관에 추가했습니다. 이를 기존의 총 권수에 더합니다: 300 + 50 = 350권.
3. 그런 다음, 학생들이 25권을 빌려갔습니다. 이를 현재의 총 권수에서 빼야 합니다: 350 - 25 = 325권.

따라서, 도서관에는 현재 325권의 책이 남아 있습니다.</code></pre>
</div>
</div>
<div id="7bed2f0a-caa3-425f-b8fc-2902d7992898" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 사고 과정을 포함한 답변</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>cot_prompt <span class="op">=</span> [</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"민수는 색연필 12자루를 가지고 있었습니다. 새 색연필 세트를 2개 받았는데, 각 세트에는 5자루가 들어있었습니다. 민수는 지금 몇 자루의 색연필을 가지고 있나요?"</span>,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"assistant"</span>,</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"민수는 처음에 12자루의 색연필을 가지고 있었습니다. 2개의 새 세트에 각각 5자루씩 들어있으므로 10자루를 추가로 받았습니다. 12 + 10 = 22. 따라서 답은 22자루입니다."</span>,</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"학교 도서관에 책이 45권 있었습니다. 15권을 학생들에게 대출해주고 새로운 책 20권을 구입했습니다. 지금 도서관에 있는 책은 몇 권인가요?"</span>,</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 생성</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(cot_prompt)</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 도서관에서는 처음에 45권의 책이 있었습니다. 15권을 학생들에게 대출했으므로 45 - 15 = 30권이 남았습니다. 그런 다음 20권의 새로운 책을 구입했으므로 30 + 20 = 50권의 책이 지금 도서관에 있습니다. 따라서 답은 50권입니다.</code></pre>
</div>
</div>
</section>
<section id="제로샷-chain-of-thought" class="level3" data-number="2.3.8">
<h3 data-number="2.3.8" class="anchored" data-anchor-id="제로샷-chain-of-thought"><span class="header-section-number">2.3.8</span> 제로샷 Chain-of-Thought</h3>
<p>모델에게 예시를 제공하는 대신에 우리는 단순히 생성형 모델에게 추론 과정을 제공하도록 요청할 수 있습니다(제로샷 chain-of-thought). 이를 위해 효과적인 다양한 형태가 있지만 흔하고 효과적인 방법 중 하나는 “단계별로 생각해 봅시다”라는 문구를 사용하는 것입니다. 이 방법은 특히 다양한 유형의 문제에 대해 빠르게 추론 과정을 얻고자 할 때 유용하며, 모델의 일반화된 추론 능력을 테스트하는 데에도 효과적입니다.</p>
<div id="3f3a6562-d55c-4601-addd-74caad83a9a0" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Zero-shot Chain-of-Thought</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>zeroshot_cot_prompt <span class="op">=</span> [</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"도서관에 책이 50권 있었습니다. 15권을 대출해주고 새로 20권을 구입했습니다. 지금 도서관에 있는 책은 몇 권인가요? 단계별로 생각해봅시다."</span>,</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 생성</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(zeroshot_cot_prompt)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 이 문제를 해결하기 위해 다음 단계를 따르겠습니다:

1. 도서관에서 시작하는 초기 책 수: 50권
2. 대출된 책 수: 15권
3. 구입한 새로운 책 수: 20권

이제 이 값을 사용하여 현재 도서관에 있는 책 수를 계산해봅시다:

1. 시작하는 초기 책 수에서 대출된 책 수를 빼줍니다: 50 - 15 = 35권
2. 이 결과에 구입한 새로운 책 수를 더합니다: 35 + 20 = 55권

따라서, 현재 도서관에는 55권의 책이 있습니다.</code></pre>
</div>
</div>
</section>
<section id="tree-of-thought-중간-단계-탐색하기" class="level3" data-number="2.3.9">
<h3 data-number="2.3.9" class="anchored" data-anchor-id="tree-of-thought-중간-단계-탐색하기"><span class="header-section-number">2.3.9</span> Tree-of-Thought: 중간 단계 탐색하기</h3>
<p>Chain-of-Thought와 자기 일관성(self-consistency)의 개념은 더 복잡한 추론을 가능하게 하기 위한 것입니다. 여러 “생각”들을 샘플링하고 이를 더 신중하게 만듦으로써 생성형 모델의 출력을 개선합니다.</p>
<div id="ceaf803c-1983-419e-a635-4a90273bef4f" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Zero-shot Tree-of-Thought</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>zeroshot_tot_prompt <span class="op">=</span> [</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"role"</span>: <span class="st">"user"</span>,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"content"</span>: <span class="st">"세 명의 다른 전문가들이 이 질문에 답하고 있다고 상상해보세요. 모든 전문가는 자신의 생각의 1단계를 적은 다음 그룹과 공유합니다. 그런 다음 모든 전문가는 다음 단계로 넘어갑니다. 만약 어느 전문가라도 자신이 틀렸다는 것을 깨닫게 되면 그 즉시 토론에서 빠집니다. 질문은 '학교 도서관에 책이 80권 있었습니다. 30권을 학생들에게 대출해주고 새로운 책 25권을 구입했습니다. 지금 도서관에 있는 책은 몇 권인가요?' 입니다. 결과에 대해 반드시 토론해주세요."</span>,</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 생성</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> pipe(zeroshot_tot_prompt)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(outputs[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> 1단계: 초기 책 수를 기억하기
80권의 책이 도서관에서 시작합니다.

2단계: 학생들에게 대출된 책 수를 계산하기
30권의 책이 학생들에게 대출됩니다.

3단계: 구입한 새로운 책 수를 계산하기
25권의 새로운 책이 도서관에 추가됩니다.

4단계: 현재 책 수를 계산하기
1단계에서 시작한 80권에서 2단계의 30권을 빼고, 그리고 3단계의 25권을 더합니다.

80 - 30 = 50
50 + 25 = 75

토론:
도서관에는 80권의 책이 시작되었습니다. 그 다음, 30권의 책이 학생들에게 대출되었습니다. 이로 인해 도서관에는 50권의 책이 남았습니다. 그 다음, 25권의 새로운 책이 도서관에 추가되었습니다. 따</code></pre>
</div>
</div>
</section>
</section>
<section id="의미론적-검색-및-검색-증강-생성" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="의미론적-검색-및-검색-증강-생성"><span class="header-section-number">2.4</span> 의미론적 검색 및 검색 증강 생성</h2>
<section id="밀집-검색-dense-retrieval" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="밀집-검색-dense-retrieval"><span class="header-section-number">2.4.1</span> 밀집 검색 (Dense Retrieval)</h3>
<p>밀집 검색은 검색 쿼리가 관련 결과와 가까울 것이라는 특성에 의존합니다.</p>
<section id="밀집-검색-주의사항" class="level4" data-number="2.4.1.1">
<h4 data-number="2.4.1.1" class="anchored" data-anchor-id="밀집-검색-주의사항"><span class="header-section-number">2.4.1.1</span> 밀집 검색 주의사항</h4>
<ul>
<li>거짓 양성: 의미적으로 유사하지만 실제로 관련이 없는 결과를 반환할 수 있습니다.</li>
<li>답변 부재: 코퍼스에 답변이 없는 경우에도 가장 가까운 결과를 반환합니다.</li>
<li>컨텍스트 손실: 단어의 정확한 일치보다는 의미적 유사성에 중점을 두기 때문에 특정 키워드나 구문을 놓칠 수 있습니다.</li>
<li>계산 비용: 대규모 데이터셋에서는 계산 비용이 높을 수 있습니다.</li>
<li>도메인 특화의 어려움: 특정 도메인의 전문 용어나 개념을 정확히 포착하기 어려울 수 있습니다.</li>
</ul>
<div id="37c83c91-0769-49bf-8622-067ac4f54643" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    DPRContextEncoder,</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    DPRContextEncoderTokenizer,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    DPRQuestionEncoder,</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    DPRQuestionEncoderTokenizer,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>question_model <span class="op">=</span> <span class="st">"facebook/dpr-question_encoder-single-nq-base"</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>context_model <span class="op">=</span> <span class="st">"facebook/dpr-ctx_encoder-single-nq-base"</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 인코더와 토크나이저 초기화</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>question_encoder <span class="op">=</span> DPRQuestionEncoder.from_pretrained(question_model)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>question_tokenizer <span class="op">=</span> DPRQuestionEncoderTokenizer.from_pretrained(question_model)</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>context_encoder <span class="op">=</span> DPRContextEncoder.from_pretrained(context_model)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>context_tokenizer <span class="op">=</span> DPRContextEncoderTokenizer.from_pretrained(context_model)</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 질문 인코딩</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">"듄의 작가는 누구인가요?"</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>question_input <span class="op">=</span> question_tokenizer(question, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>question_embedding <span class="op">=</span> question_encoder(<span class="op">**</span>question_input).pooler_output</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 컨텍스트 인코딩</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>context <span class="op">=</span> <span class="st">"듄은 1965년에 미국 작가 프랭크 허버트가 쓴 공상과학 소설입니다."</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>context_input <span class="op">=</span> context_tokenizer(context, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>context_embedding <span class="op">=</span> context_encoder(<span class="op">**</span>context_input).pooler_output</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 유사도 계산</span></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>similarity <span class="op">=</span> torch.matmul(question_embedding, context_embedding.transpose(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"유사도 점수: </span><span class="sc">{</span>similarity<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>유사도 점수: 75.5189</code></pre>
</div>
</div>
</section>
</section>
<section id="재순위화-예시" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="재순위화-예시"><span class="header-section-number">2.4.2</span> 재순위화 예시</h3>
<p>재순위화 시스템(예: monoBERT)은 사용자의 검색어와 후보 결과들을 분석하여 각 문서가 해당 검색어와 얼마나 관련이 있는지 점수를 매깁니다. 이렇게 산출된 관련성 점수를 바탕으로 사전에 선별된 결과들의 순서를 재배열합니다. 이 과정을 통해 검색어에 대한 결과의 순위가 개선되어 더욱 정확하고 관련성 높은 정보를 상위에 표시할 수 있게 됩니다.</p>
<p>재순위화 시스템의 주요 특징은 다음과 같습니다:</p>
<ol type="1">
<li><p><strong>정교한 관련성 평가</strong>: 단순한 키워드 매칭을 넘어 문맥과 의미를 고려한 심층적인 관련성 평가를 수행합니다.</p></li>
<li><p><strong>맞춤형 순위 조정</strong>: 사용자의 검색 의도를 더 정확히 반영하여 결과의 순위를 조정합니다.</p></li>
<li><p><strong>검색 품질 향상</strong>: 사용자에게 더 관련성 높고 유용한 정보를 우선적으로 제공함으로써 전반적인 검색 경험을 개선합니다.</p></li>
<li><p><strong>다양한 요소 고려</strong>: 문서의 내용, 구조, 메타데이터 등 다양한 요소를 종합적으로 분석하여 순위를 결정합니다.</p></li>
</ol>
<div id="d00362ee-9825-468f-a103-1c099b0d487b" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification, AutoTokenizer</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"cross-encoder/ms-marco-MiniLM-L-6-v2"</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 재순위화 모델 로드</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_name)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 예시 쿼리와 검색된 문단들</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"프랑스의 수도는 어디인가요?"</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>passages <span class="op">=</span> [</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"파리는 프랑스의 수도이자 가장 인구가 많은 도시입니다."</span>,</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"런던은 영국과 잉글랜드의 수도입니다."</span>,</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"프랑스는 서유럽에 위치한 국가입니다."</span>,</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 문단 재순위화</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>pairs <span class="op">=</span> [[query, passage] <span class="cf">for</span> passage <span class="kw">in</span> passages]</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(pairs, padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> model(<span class="op">**</span>inputs).logits.squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 점수에 따라 문단 정렬</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>reranked_passages <span class="op">=</span> [p <span class="cf">for</span> _, p <span class="kw">in</span> <span class="bu">sorted</span>(<span class="bu">zip</span>(scores, passages), reverse<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"재순위화된 문단:"</span>)</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, passage <span class="kw">in</span> <span class="bu">enumerate</span>(reranked_passages, <span class="dv">1</span>):</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">. </span><span class="sc">{</span>passage<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>재순위화된 문단:
1. 파리는 프랑스의 수도이자 가장 인구가 많은 도시입니다.
2. 런던은 영국과 잉글랜드의 수도입니다.
3. 프랑스는 서유럽에 위치한 국가입니다.</code></pre>
</div>
</div>
</section>
<section id="rag검색-증강-생성" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="rag검색-증강-생성"><span class="header-section-number">2.4.3</span> RAG(검색 증강 생성)</h3>
<p>RAG는 검색 시스템의 파이프라인 끝단에 생성형 대규모 언어 모델(LLM)을 배치하는 혁신적인 접근 방식입니다. 이 방법을 통해 시스템은 검색된 문서를 바탕으로 답변을 생성하면서 동시에 출처를 인용할 수 있습니다. RAG의 주요 특징과 장점은 다음과 같습니다:</p>
<ol type="1">
<li><p><strong>정보의 정확성과 최신성</strong>: 실시간으로 검색된 최신 정보를 바탕으로 답변을 생성하므로, 항상 최신의 정확한 정보를 제공할 수 있습니다.</p></li>
<li><p><strong>근거 기반 응답</strong>: 생성된 답변의 각 부분에 대해 출처를 제시함으로써, 사용자는 정보의 신뢰성을 직접 확인할 수 있습니다.</p></li>
<li><p><strong>유연한 지식 확장</strong>: 모델의 재학습 없이도 새로운 정보를 즉시 활용할 수 있어, 지식 기반을 지속적으로 확장할 수 있습니다.</p></li>
<li><p><strong>맥락 이해 능력 향상</strong>: 검색된 문서들의 맥락을 종합적으로 이해하여 더 깊이 있고 관련성 높은 답변을 생성합니다.</p></li>
<li><p><strong>투명성 제고</strong>: 정보의 출처를 명확히 제시함으로써 AI 시스템의 의사결정 과정을 더 투명하게 만듭니다.</p></li>
</ol>
<div id="6ed63a14-a595-4d5e-ac66-fa62c45f197e" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    AutoModel,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    RagRetriever,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    RagSequenceForGeneration,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 사전 훈련된 모델 로드</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>question_encoder <span class="op">=</span> AutoModel.from_pretrained(<span class="st">"facebook/dpr-question_encoder-single-nq-base"</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>question_tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"facebook/dpr-question_encoder-single-nq-base"</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>generator_tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"facebook/bart-large"</span>)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co"># RAG 컴포넌트 초기화</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>retriever <span class="op">=</span> RagRetriever.from_pretrained(</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"facebook/rag-sequence-nq"</span>, index_name<span class="op">=</span><span class="st">"exact"</span>, use_dummy_dataset<span class="op">=</span><span class="va">True</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RagSequenceForGeneration.from_pretrained(<span class="st">"facebook/rag-sequence-nq"</span>, retriever<span class="op">=</span>retriever)</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_answer(query):</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 쿼리 인코딩</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> question_tokenizer(query, return_tensors<span class="op">=</span><span class="st">"pt"</span>)[<span class="st">"input_ids"</span>]</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>    question_hidden_states <span class="op">=</span> question_encoder(input_ids)[<span class="dv">0</span>]</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 관련 문서 검색</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>    retriever_output <span class="op">=</span> retriever(input_ids, question_hidden_states, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 답변 생성</span></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> retriever_output[<span class="st">"input_ids"</span>]</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>    attention_mask <span class="op">=</span> retriever_output[<span class="st">"attention_mask"</span>]</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model.generate(input_ids<span class="op">=</span>input_ids, attention_mask<span class="op">=</span>attention_mask)</span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 생성된 답변 디코딩 및 반환</span></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> generator_tokenizer.decode(output[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a><span class="co"># 사용 예시</span></span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"프랑스의 수도는 어디인가요?"</span></span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a>answer <span class="op">=</span> generate_answer(query)</span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"질문: </span><span class="sc">{</span>query<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"답변: </span><span class="sc">{</span>answer<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="멀티모달-llm" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="멀티모달-llm"><span class="header-section-number">2.5</span> 멀티모달 LLM</h2>
<p>대규모 언어 모델(LLM)에서는 멀티모달 입력을 받아들이고 이를 바탕으로 추론하는 능력은 이전에는 접근하기 어려웠던 새로운 가능성을 열어줄 수 있습니다. 여기에서는 멀티모달 기능을 갖춘 여러 LLM을 살펴보고 실제 사용 사례로 어떤 의미를 갖는지 알아볼 것입니다.</p>
<section id="clip텍스트와-이미지-연결" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="clip텍스트와-이미지-연결"><span class="header-section-number">2.5.1</span> CLIP(텍스트와 이미지 연결)</h3>
<p>CLIP은 이미지와 텍스트 모두의 임베딩을 계산할 수 있는 임베딩 모델입니다. CLIP은 컴퓨터 비전과 자연어 처리의 경계를 허물고 두 영역을 통합하는 강력한 도구로 자리잡고 있습니다. 이를 통해 AI 시스템은 인간의 의사소통 방식에 더 가까워지고 더욱 자연스럽고 직관적인 상호작용이 가능해집니다. CLIP의 주요 특징은 다음과 같습니다:</p>
<ol type="1">
<li><strong>통합된 표현 공간</strong>: 이미지와 텍스트를 동일한 벡터 공간에 표현하여 직접적인 비교가 가능합니다.</li>
<li><strong>크로스모달 학습</strong>: 이미지와 텍스트 사이의 관계를 학습하여 더 풍부한 이해를 가능하게 합니다.</li>
<li><strong>유연한 응용</strong>: 이미지 검색, 이미지 캡셔닝, 시각적 질의응답 등 다양한 작업에 활용될 수 있습니다.</li>
<li><strong>제로샷 학습 능력</strong>: 특정 작업에 대한 추가 학습 없이도 새로운 개념을 인식할 수 있습니다.</li>
</ol>
<div id="99779707-b686-4c95-8097-a873a54b9772" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> urllib.request <span class="im">import</span> urlopen</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> CLIPModel, CLIPProcessor, CLIPTokenizerFast</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 불러오기</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>image_url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/chapter09/images/puppy.png"</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> Image.<span class="bu">open</span>(urlopen(image_url)).convert(<span class="st">"RGB"</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>caption <span class="op">=</span> <span class="st">"A ppuppy playing in the snow"</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"openai/clip-vit-base-patch32"</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 텍스트 전처리를 위한 토크나이저 로드</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>clip_tokenizer <span class="op">=</span> CLIPTokenizerFast.from_pretrained(model_id)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 전처리를 위한 프로세서 로드</span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>clip_processor <span class="op">=</span> CLIPProcessor.from_pretrained(model_id)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 텍스트 및 이미지 임베딩 생성을 위한 주 모델</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> CLIPModel.from_pretrained(model_id)</span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 입력 토큰화</span></span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> clip_tokenizer(caption, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 텍스트 임베딩 생성</span></span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a>text_embedding <span class="op">=</span> model.get_text_features(<span class="op">**</span>inputs)</span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 전처리</span></span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a>processed_image <span class="op">=</span> clip_processor(text<span class="op">=</span><span class="va">None</span>, images<span class="op">=</span>image, return_tensors<span class="op">=</span><span class="st">"pt"</span>)[<span class="st">"pixel_values"</span>]</span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 임베딩 생성</span></span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a>image_embedding <span class="op">=</span> model.get_image_features(processed_image)</span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a><span class="co"># 시각화를 위한 이미지 준비</span></span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>processed_img <span class="op">=</span> processed_image.squeeze(<span class="dv">0</span>)</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a>processed_img <span class="op">=</span> processed_img.permute(<span class="op">*</span>torch.arange(processed_img.ndim <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a>processed_img <span class="op">=</span> np.einsum(<span class="st">"ijk-&gt;jik"</span>, processed_img.numpy())</span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a><span class="co"># 원본 이미지와 처리된 이미지 시각화</span></span>
<span id="cb41-42"><a href="#cb41-42" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb41-43"><a href="#cb41-43" aria-hidden="true" tabindex="-1"></a>ax1.imshow(image)</span>
<span id="cb41-44"><a href="#cb41-44" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">"Original Image"</span>)</span>
<span id="cb41-45"><a href="#cb41-45" aria-hidden="true" tabindex="-1"></a>ax1.axis(<span class="st">"off"</span>)</span>
<span id="cb41-46"><a href="#cb41-46" aria-hidden="true" tabindex="-1"></a>ax2.imshow(processed_img)</span>
<span id="cb41-47"><a href="#cb41-47" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">"Processed Image"</span>)</span>
<span id="cb41-48"><a href="#cb41-48" aria-hidden="true" tabindex="-1"></a>ax2.axis(<span class="st">"off"</span>)</span>
<span id="cb41-49"><a href="#cb41-49" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb41-50"><a href="#cb41-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-51"><a href="#cb41-51" aria-hidden="true" tabindex="-1"></a><span class="co"># 임베딩 정규화</span></span>
<span id="cb41-52"><a href="#cb41-52" aria-hidden="true" tabindex="-1"></a>text_embedding <span class="op">/=</span> text_embedding.norm(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-53"><a href="#cb41-53" aria-hidden="true" tabindex="-1"></a>image_embedding <span class="op">/=</span> image_embedding.norm(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-54"><a href="#cb41-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-55"><a href="#cb41-55" aria-hidden="true" tabindex="-1"></a><span class="co"># 유사도 계산</span></span>
<span id="cb41-56"><a href="#cb41-56" aria-hidden="true" tabindex="-1"></a>text_embedding <span class="op">=</span> text_embedding.detach().cpu().numpy()</span>
<span id="cb41-57"><a href="#cb41-57" aria-hidden="true" tabindex="-1"></a>image_embedding <span class="op">=</span> image_embedding.detach().cpu().numpy()</span>
<span id="cb41-58"><a href="#cb41-58" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> text_embedding <span class="op">@</span> image_embedding.T</span>
<span id="cb41-59"><a href="#cb41-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"유사도 점수: </span><span class="sc">{</span>score<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.7922626..2.145897].</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="LLM_HansOnLLM_files/figure-html/cell-27-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="LLM_HansOnLLM_files/figure-html/cell-27-output-2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>유사도 점수: 0.3006</code></pre>
</div>
</div>
</section>
<section id="blip-2양식-간-격차-해소" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="blip-2양식-간-격차-해소"><span class="header-section-number">2.5.2</span> BLIP-2(양식 간 격차 해소)</h3>
<p>처음부터 멀티모달 언어 모델을 만드는 것은 엄청난 컴퓨팅 파워와 데이터를 필요로 합니다. 이러한 모델을 만들려면 수십억 개의 이미지, 텍스트, 그리고 이미지-텍스트 쌍을 사용해야 합니다. 이는 쉽게 실현 가능한 일이 아닙니다. BLIP-2는 이러한 어려움을 해결하기 위해 새로운 접근 방식을 취합니다. 처음부터 아키텍처를 구축하는 대신, 사전 학습된 이미지 인코더와 사전 학습된 LLM을 연결하는 ’쿼리 트랜스포머(Q-Former)’라는 다리를 구축하여 시각-언어 간의 격차를 해소합니다. 이 방식의 주요 장점은 다음과 같습니다:</p>
<ol type="1">
<li><strong>효율적인 학습</strong>: BLIP-2는 이미지 인코더와 LLM을 처음부터 학습할 필요 없이 연결 다리만 학습하면 됩니다.</li>
<li><strong>기존 기술 활용</strong>: 이미 존재하는 기술과 모델을 최대한 활용하여 효율성을 높입니다.</li>
<li><strong>유연성</strong>: 다양한 사전 학습 모델을 조합하여 사용할 수 있어, 특정 작업에 최적화된 구성을 만들 수 있습니다.</li>
<li><strong>성능 향상</strong>: 각 분야에서 최고의 성능을 보이는 모델들을 결합함으로써 전반적인 성능을 크게 향상시킬 수 있습니다.</li>
<li><strong>자원 절약</strong>: 거대한 데이터셋과 컴퓨팅 자원이 필요한 전체 모델 학습을 피할 수 있어 시간과 비용을 절약합니다.</li>
</ol>
<div id="bde289aa-d173-4b78-ba76-ce78ac68a2eb" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> urllib.request <span class="im">import</span> urlopen</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForVisualQuestionAnswering, AutoProcessor</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 프로세서와 주 모델 로드</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>blip_processor <span class="op">=</span> AutoProcessor.from_pretrained(</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Salesforce/blip2-opt-2.7b"</span>,</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForVisualQuestionAnswering.from_pretrained(</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Salesforce/blip2-opt-2.7b"</span>, torch_dtype<span class="op">=</span>torch.float16</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 추론 속도 향상을 위해 모델을 GPU로 이동</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 슈퍼카 이미지 로드</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>car_path <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/chapter09/images/car.png"</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> Image.<span class="bu">open</span>(urlopen(car_path)).convert(<span class="st">"RGB"</span>)</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 전처리</span></span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> blip_processor(image, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(device, torch.float16)</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a>inputs[<span class="st">"pixel_values"</span>].shape</span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a><span class="co"># numpy로 변환하고 (1, 3, 224, 224)에서 (224, 224, 3) 형태로 변경</span></span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a>image_inputs <span class="op">=</span> inputs[<span class="st">"pixel_values"</span>][<span class="dv">0</span>].detach().cpu().numpy()</span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a>image_inputs <span class="op">=</span> np.einsum(<span class="st">"ijk-&gt;kji"</span>, image_inputs)</span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a>image_inputs <span class="op">=</span> np.einsum(<span class="st">"ijk-&gt;jik"</span>, image_inputs)</span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a><span class="co"># RGB 값을 나타내기 위해 이미지 입력을 0-255로 스케일링</span></span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>))</span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a>image_inputs <span class="op">=</span> scaler.fit_transform(image_inputs.reshape(<span class="op">-</span><span class="dv">1</span>, image_inputs.shape[<span class="op">-</span><span class="dv">1</span>])).reshape(</span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a>    image_inputs.shape</span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a>image_inputs <span class="op">=</span> np.array(image_inputs, dtype<span class="op">=</span>np.uint8)</span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a><span class="co"># numpy 배열을 Image로 변환</span></span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a>Image.fromarray(image_inputs)</span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a><span class="co"># 텍스트 전처리</span></span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Her vocalization was remarkably melodic"</span></span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a>token_ids <span class="op">=</span> blip_processor(image, text<span class="op">=</span>text, return_tensors<span class="op">=</span><span class="st">"pt"</span>)</span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a>token_ids <span class="op">=</span> token_ids.to(device, torch.float16)[<span class="st">"input_ids"</span>][<span class="dv">0</span>]</span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a><span class="co"># 입력 ID를 다시 토큰으로 변환</span></span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> blip_processor.tokenizer.convert_ids_to_tokens(token_ids)</span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a><span class="co"># 공백 토큰을 밑줄로 대체</span></span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> [token.replace(<span class="st">"Ġ"</span>, <span class="st">"_"</span>) <span class="cf">for</span> token <span class="kw">in</span> tokens]</span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-56"><a href="#cb44-56" aria-hidden="true" tabindex="-1"></a><span class="co"># 시각화</span></span>
<span id="cb44-57"><a href="#cb44-57" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb44-58"><a href="#cb44-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-59"><a href="#cb44-59" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 표시</span></span>
<span id="cb44-60"><a href="#cb44-60" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb44-61"><a href="#cb44-61" aria-hidden="true" tabindex="-1"></a>plt.imshow(Image.fromarray(image_inputs))</span>
<span id="cb44-62"><a href="#cb44-62" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Processed Image"</span>)</span>
<span id="cb44-63"><a href="#cb44-63" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb44-64"><a href="#cb44-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-65"><a href="#cb44-65" aria-hidden="true" tabindex="-1"></a><span class="co"># 텍스트와 토큰 표시</span></span>
<span id="cb44-66"><a href="#cb44-66" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb44-67"><a href="#cb44-67" aria-hidden="true" tabindex="-1"></a>plt.text(</span>
<span id="cb44-68"><a href="#cb44-68" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.5</span>,</span>
<span id="cb44-69"><a href="#cb44-69" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.9</span>,</span>
<span id="cb44-70"><a href="#cb44-70" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f"Original Text: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb44-71"><a href="#cb44-71" aria-hidden="true" tabindex="-1"></a>    horizontalalignment<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb44-72"><a href="#cb44-72" aria-hidden="true" tabindex="-1"></a>    fontsize<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb44-73"><a href="#cb44-73" aria-hidden="true" tabindex="-1"></a>    wrap<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb44-74"><a href="#cb44-74" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-75"><a href="#cb44-75" aria-hidden="true" tabindex="-1"></a>plt.text(<span class="fl">0.5</span>, <span class="fl">0.65</span>, <span class="st">"Tokens:"</span>, horizontalalignment<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb44-76"><a href="#cb44-76" aria-hidden="true" tabindex="-1"></a>plt.text(<span class="fl">0.5</span>, <span class="fl">0.2</span>, <span class="st">" "</span>.join(tokens), horizontalalignment<span class="op">=</span><span class="st">"center"</span>, fontsize<span class="op">=</span><span class="dv">10</span>, wrap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb44-77"><a href="#cb44-77" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb44-78"><a href="#cb44-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-79"><a href="#cb44-79" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb44-80"><a href="#cb44-80" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a25bfc74cfed4c89b2c3579fc125a259","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="LLM_HansOnLLM_files/figure-html/cell-28-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="LLM_HansOnLLM_files/figure-html/cell-28-output-2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<section id="사용-사례-1-이미지-캡셔닝" class="level4" data-number="2.5.2.1">
<h4 data-number="2.5.2.1" class="anchored" data-anchor-id="사용-사례-1-이미지-캡셔닝"><span class="header-section-number">2.5.2.1</span> 사용 사례 1: 이미지 캡셔닝</h4>
<p>이미지 캡셔닝은 주어진 이미지의 내용을 설명하는 텍스트를 자동으로 생성하는 작업입니다.</p>
<div id="a25f15e8-2a8d-4ad4-91cb-098e3543ca84" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 로드</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://upload.wikimedia.org/wikipedia/commons/7/70/Rorschach_blot_01.jpg"</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> Image.<span class="bu">open</span>(urlopen(url)).convert(<span class="st">"RGB"</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 캡션 생성</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> blip_processor(image, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(device, torch.float16)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>generated_ids <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>generated_text <span class="op">=</span> blip_processor.batch_decode(generated_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>generated_text <span class="op">=</span> generated_text[<span class="dv">0</span>].strip()</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지와 생성된 텍스트 시각화</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>plt.imshow(image)</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Generated text: </span><span class="sc">{</span>generated_text<span class="sc">}</span><span class="ss">"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="LLM_HansOnLLM_files/figure-html/cell-29-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="LLM_HansOnLLM_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="사용-사례-2-시각적-질의응답" class="level4" data-number="2.5.2.2">
<h4 data-number="2.5.2.2" class="anchored" data-anchor-id="사용-사례-2-시각적-질의응답"><span class="header-section-number">2.5.2.2</span> 사용 사례 2: 시각적 질의응답</h4>
<p>시각적 질의응답은 이미지와 관련된 질문에 대해 AI가 답변을 제공하는 기술입니다.</p>
<div id="351719c7-29be-4494-928f-2783627a8890" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지 로드</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://upload.wikimedia.org/wikipedia/commons/7/70/Rorschach_blot_01.jpg"</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> Image.<span class="bu">open</span>(urlopen(url)).convert(<span class="st">"RGB"</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 시각적 질문 답변</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Question: Write down what you see in this picture. Answer:"</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지와 프롬프트 처리</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> blip_processor(image, text<span class="op">=</span>prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(device, torch.float16)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 텍스트 생성</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>generated_ids <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>generated_text <span class="op">=</span> blip_processor.batch_decode(generated_ids, skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>generated_text <span class="op">=</span> generated_text[<span class="dv">0</span>].strip()</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지와 생성된 텍스트 시각화</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>plt.imshow(image)</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"</span><span class="sc">{</span>generated_text<span class="sc">}</span><span class="ss">"</span>, fontsize<span class="op">=</span><span class="dv">12</span>, wrap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="LLM_HansOnLLM_files/figure-html/cell-30-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="LLM_HansOnLLM_files/figure-html/cell-30-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>이러한 다중 모달 텍스트 생성 모델의 핵심 아이디어는 입력 이미지의 시각적 특징을 LLM이 사용할 수 있는 텍스트 임베딩으로 투영하는 것입니다. 이 모델을 이미지 캡셔닝과 다중 모달 채팅 기반 프롬프팅에 사용하는 방법을 보았는데, 여기서는 두 가지 양식을 결합하여 응답을 생성합니다.</p>
</section>
</section>
</section>
</section>
<section id="언어-모델-훈련-및-미세-조정" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> 언어 모델 훈련 및 미세 조정</h1>
<section id="텍스트-임베딩-모델-생성" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="텍스트-임베딩-모델-생성"><span class="header-section-number">3.1</span> 텍스트 임베딩 모델 생성</h2>
<p>텍스트 임베딩 모델은 많은 강력한 자연어 처리 애플리케이션의 기초를 이룹니다. 이들은 텍스트 생성 모델과 같은 이미 인상적인 기술들을 더욱 강화하는 기반을 마련합니다. 임베딩 모델을 생성하는 방법은 여러 가지가 있지만, 일반적으로 우리는 대조 학습을 주목합니다. 이는 많은 임베딩 모델의 중요한 측면인데, 이 과정을 통해 모델이 의미론적 표현을 효율적으로 학습할 수 있기 때문입니다.</p>
<section id="대조-생성generating-contrastive-예제" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="대조-생성generating-contrastive-예제"><span class="header-section-number">3.1.1</span> 대조 생성(Generating Contrastive) 예제</h3>
<div id="a8697927-06bb-485b-90b4-f51329ede4a4" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset, load_dataset</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer, losses</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.evaluation <span class="im">import</span> EmbeddingSimilarityEvaluator</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.trainer <span class="im">import</span> SentenceTransformerTrainer</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.training_args <span class="im">import</span> SentenceTransformerTrainingArguments</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="co"># GLUE에서 MNLI 데이터셋 로드</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>mnli <span class="op">=</span> load_dataset(<span class="st">"glue"</span>, <span class="st">"mnli"</span>, split<span class="op">=</span><span class="st">"train"</span>).select(<span class="bu">range</span>(<span class="dv">50_000</span>))</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>mnli <span class="op">=</span> mnli.remove_columns(<span class="st">"idx"</span>)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>mnli <span class="op">=</span> mnli.<span class="bu">filter</span>(<span class="kw">lambda</span> x: <span class="va">True</span> <span class="cf">if</span> x[<span class="st">"label"</span>] <span class="op">==</span> <span class="dv">0</span> <span class="cf">else</span> <span class="va">False</span>)</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터 전처리</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> {<span class="st">"anchor"</span>: [], <span class="st">"positive"</span>: [], <span class="st">"negative"</span>: []}</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>soft_negatives <span class="op">=</span> mnli[<span class="st">"hypothesis"</span>]</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>random.shuffle(soft_negatives)</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row, soft_negative <span class="kw">in</span> tqdm(<span class="bu">zip</span>(mnli, soft_negatives)):</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>    train_dataset[<span class="st">"anchor"</span>].append(row[<span class="st">"premise"</span>])</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a>    train_dataset[<span class="st">"positive"</span>].append(row[<span class="st">"hypothesis"</span>])</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a>    train_dataset[<span class="st">"negative"</span>].append(soft_negative)</span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> Dataset.from_dict(train_dataset)</span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델</span></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> SentenceTransformer(<span class="st">"bert-base-uncased"</span>)</span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 손실 함수 정의. 소프트맥스 손실에서는 레이블 수를 명시적으로 설정해야 함.</span></span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> losses.MultipleNegativesRankingLoss(model<span class="op">=</span>embedding_model)</span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 평가 함수 및 stsb를 위한 임베딩 유사도 평가기 생성</span></span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a>val_sts <span class="op">=</span> load_dataset(<span class="st">"glue"</span>, <span class="st">"stsb"</span>, split<span class="op">=</span><span class="st">"validation"</span>)</span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a>evaluator <span class="op">=</span> EmbeddingSimilarityEvaluator(</span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a>    sentences1<span class="op">=</span>val_sts[<span class="st">"sentence1"</span>],</span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a>    sentences2<span class="op">=</span>val_sts[<span class="st">"sentence2"</span>],</span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a>    scores<span class="op">=</span>[score <span class="op">/</span> <span class="dv">5</span> <span class="cf">for</span> score <span class="kw">in</span> val_sts[<span class="st">"label"</span>]],</span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a>    main_similarity<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 인자 정의</span></span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> SentenceTransformerTrainingArguments(</span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"mnrloss_embedding_model"</span>,</span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb47-46"><a href="#cb47-46" aria-hidden="true" tabindex="-1"></a>    warmup_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb47-47"><a href="#cb47-47" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb47-48"><a href="#cb47-48" aria-hidden="true" tabindex="-1"></a>    eval_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb47-49"><a href="#cb47-49" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb47-50"><a href="#cb47-50" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-51"><a href="#cb47-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-52"><a href="#cb47-52" aria-hidden="true" tabindex="-1"></a><span class="co"># 임베딩 모델 훈련</span></span>
<span id="cb47-53"><a href="#cb47-53" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> SentenceTransformerTrainer(</span>
<span id="cb47-54"><a href="#cb47-54" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>embedding_model,</span>
<span id="cb47-55"><a href="#cb47-55" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>args,</span>
<span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb47-57"><a href="#cb47-57" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span>train_loss,</span>
<span id="cb47-58"><a href="#cb47-58" aria-hidden="true" tabindex="-1"></a>    evaluator<span class="op">=</span>evaluator,</span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련된 모델 평가</span></span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a>evaluator(embedding_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>16875it [00:00, 42644.51it/s]
No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
      
      <progress value="528" max="528" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [528/528 00:32, Epoch 1/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100</td>
<td>0.346900</td>
</tr>
<tr class="even">
<td>200</td>
<td>0.107100</td>
</tr>
<tr class="odd">
<td>300</td>
<td>0.083700</td>
</tr>
<tr class="even">
<td>400</td>
<td>0.068100</td>
</tr>
<tr class="odd">
<td>500</td>
<td>0.072500</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"89f595417aa44ce5b88220d312bf2161","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>{'pearson_cosine': np.float64(0.8058287434682441),
 'spearman_cosine': np.float64(0.8093139517546301)}</code></pre>
</div>
</div>
</section>
<section id="임베딩-모델의-미세-조정" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="임베딩-모델의-미세-조정"><span class="header-section-number">3.1.2</span> 임베딩 모델의 미세 조정</h3>
<section id="지도-학습-기반-미세-조정-supervised-fine-tuning-sft" class="level4" data-number="3.1.2.1">
<h4 data-number="3.1.2.1" class="anchored" data-anchor-id="지도-학습-기반-미세-조정-supervised-fine-tuning-sft"><span class="header-section-number">3.1.2.1</span> 지도 학습 기반 미세 조정 (Supervised Fine-Tuning, SFT)</h4>
<p>지도 학습 기반 미세 조정(SFT)은 사전 훈련된 임베딩 모델을 특정 작업이나 도메인에 맞게 조정하는 프로세스입니다. 이 방법은 레이블이 지정된 데이터셋을 사용하여 모델의 성능을 향상시키고 특정 용도에 더 적합하게 만듭니다.</p>
<div id="58ccae0b-854e-463d-b0ee-683ea5a085ac" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer, losses</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.evaluation <span class="im">import</span> EmbeddingSimilarityEvaluator</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.trainer <span class="im">import</span> SentenceTransformerTrainer</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.training_args <span class="im">import</span> SentenceTransformerTrainingArguments</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># GLUE에서 MNLI 데이터셋 로드</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 0 = 함의, 1 = 중립, 2 = 모순</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> load_dataset(<span class="st">"glue"</span>, <span class="st">"mnli"</span>, split<span class="op">=</span><span class="st">"train"</span>).select(<span class="bu">range</span>(<span class="dv">25_000</span>))</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.remove_columns(<span class="st">"idx"</span>)</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="co"># stsb를 위한 임베딩 유사도 평가기 생성</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>val_sts <span class="op">=</span> load_dataset(<span class="st">"glue"</span>, <span class="st">"stsb"</span>, split<span class="op">=</span><span class="st">"validation"</span>)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>evaluator <span class="op">=</span> EmbeddingSimilarityEvaluator(</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>    sentences1<span class="op">=</span>val_sts[<span class="st">"sentence1"</span>],</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>    sentences2<span class="op">=</span>val_sts[<span class="st">"sentence2"</span>],</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    scores<span class="op">=</span>[score <span class="op">/</span> <span class="dv">5</span> <span class="cf">for</span> score <span class="kw">in</span> val_sts[<span class="st">"label"</span>]],</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>    main_similarity<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 정의</span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> SentenceTransformer(<span class="st">"sentence-transformers/all-MiniLM-L6-v2"</span>)</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 손실 함수</span></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> losses.MultipleNegativesRankingLoss(model<span class="op">=</span>embedding_model)</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 인자 정의</span></span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> SentenceTransformerTrainingArguments(</span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"finetuned_embedding_model"</span>,</span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a>    warmup_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb50-35"><a href="#cb50-35" aria-hidden="true" tabindex="-1"></a>    eval_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb50-36"><a href="#cb50-36" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb50-37"><a href="#cb50-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-38"><a href="#cb50-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-39"><a href="#cb50-39" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 훈련</span></span>
<span id="cb50-40"><a href="#cb50-40" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> SentenceTransformerTrainer(</span>
<span id="cb50-41"><a href="#cb50-41" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>embedding_model,</span>
<span id="cb50-42"><a href="#cb50-42" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>args,</span>
<span id="cb50-43"><a href="#cb50-43" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb50-44"><a href="#cb50-44" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span>train_loss,</span>
<span id="cb50-45"><a href="#cb50-45" aria-hidden="true" tabindex="-1"></a>    evaluator<span class="op">=</span>evaluator,</span>
<span id="cb50-46"><a href="#cb50-46" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb50-47"><a href="#cb50-47" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb50-48"><a href="#cb50-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-49"><a href="#cb50-49" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련된 모델 평가</span></span>
<span id="cb50-50"><a href="#cb50-50" aria-hidden="true" tabindex="-1"></a>evaluator(embedding_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:
dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
      
      <progress value="782" max="782" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [782/782 00:20, Epoch 1/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100</td>
<td>0.127500</td>
</tr>
<tr class="even">
<td>200</td>
<td>0.126100</td>
</tr>
<tr class="odd">
<td>300</td>
<td>0.108700</td>
</tr>
<tr class="even">
<td>400</td>
<td>0.117500</td>
</tr>
<tr class="odd">
<td>500</td>
<td>0.115400</td>
</tr>
<tr class="even">
<td>600</td>
<td>0.105800</td>
</tr>
<tr class="odd">
<td>700</td>
<td>0.106100</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6c25295376e34b8a947275510261363d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>{'pearson_cosine': np.float64(0.850360102427649),
 'spearman_cosine': np.float64(0.8505789375274108)}</code></pre>
</div>
</div>
</section>
</section>
<section id="비지도-학습" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="비지도-학습"><span class="header-section-number">3.1.3</span> 비지도 학습</h3>
<p>현실 세계의 데이터셋에는 우리가 사용할 수 있는 좋은 레이블 세트가 함께 제공되지 않습니다. 대신 미리 정해진 레이블 없이 모델을 훈련시키는 기법을 찾아야 합니다. 이것을 비지도 학습이라 부릅니다. 여기에는 여러 가지 방식이 존재합니다.</p>
<section id="트랜스포머-기반-순차적-디노이징-오토인코더" class="level4" data-number="3.1.3.1">
<h4 data-number="3.1.3.1" class="anchored" data-anchor-id="트랜스포머-기반-순차적-디노이징-오토인코더"><span class="header-section-number">3.1.3.1</span> 트랜스포머 기반 순차적 디노이징 오토인코더</h4>
<p>TSDAE는 비지도 학습으로 임베딩 모델을 만드는 매우 우아한 접근 방식입니다. 이 방법은 우리가 전혀 레이블이 지정된 데이터를 가지고 있지 않다고 가정하며, 인위적으로 레이블을 만들 필요가 없습니다.</p>
<div id="7f90a3ab-331f-4c5e-86a9-a9ec0a090959" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset, load_dataset</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer, losses, models</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.datasets <span class="im">import</span> DenoisingAutoEncoderDataset</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.evaluation <span class="im">import</span> EmbeddingSimilarityEvaluator</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.trainer <span class="im">import</span> SentenceTransformerTrainer</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers.training_args <span class="im">import</span> SentenceTransformerTrainingArguments</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 추가 토크나이저 다운로드</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">"punkt"</span>)</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">"punkt_tab"</span>)</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 문장의 평면 리스트 생성</span></span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>mnli <span class="op">=</span> load_dataset(<span class="st">"glue"</span>, <span class="st">"mnli"</span>, split<span class="op">=</span><span class="st">"train"</span>).select(<span class="bu">range</span>(<span class="dv">25_000</span>))</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>flat_sentences <span class="op">=</span> mnli[<span class="st">"premise"</span>] <span class="op">+</span> mnli[<span class="st">"hypothesis"</span>]</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 입력 데이터에 노이즈 추가</span></span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>damaged_data <span class="op">=</span> DenoisingAutoEncoderDataset(<span class="bu">list</span>(<span class="bu">set</span>(flat_sentences)))</span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터셋 생성</span></span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> {<span class="st">"damaged_sentence"</span>: [], <span class="st">"original_sentence"</span>: []}</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data <span class="kw">in</span> tqdm(damaged_data):</span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>    train_dataset[<span class="st">"damaged_sentence"</span>].append(data.texts[<span class="dv">0</span>])</span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a>    train_dataset[<span class="st">"original_sentence"</span>].append(data.texts[<span class="dv">1</span>])</span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> Dataset.from_dict(train_dataset)</span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a><span class="co"># stsb를 위한 임베딩 유사도 평가기 생성</span></span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a>val_sts <span class="op">=</span> load_dataset(<span class="st">"glue"</span>, <span class="st">"stsb"</span>, split<span class="op">=</span><span class="st">"validation"</span>)</span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a>evaluator <span class="op">=</span> EmbeddingSimilarityEvaluator(</span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a>    sentences1<span class="op">=</span>val_sts[<span class="st">"sentence1"</span>],</span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a>    sentences2<span class="op">=</span>val_sts[<span class="st">"sentence2"</span>],</span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>    scores<span class="op">=</span>[score <span class="op">/</span> <span class="dv">5</span> <span class="cf">for</span> score <span class="kw">in</span> val_sts[<span class="st">"label"</span>]],</span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a>    main_similarity<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a><span class="co"># 임베딩 모델 생성</span></span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a>word_embedding_model <span class="op">=</span> models.Transformer(<span class="st">"bert-base-uncased"</span>)</span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a>pooling_model <span class="op">=</span> models.Pooling(word_embedding_model.get_word_embedding_dimension(), <span class="st">"cls"</span>)</span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> SentenceTransformer(modules<span class="op">=</span>[word_embedding_model, pooling_model])</span>
<span id="cb53-41"><a href="#cb53-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-42"><a href="#cb53-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 디노이징 오토인코더 손실 사용</span></span>
<span id="cb53-43"><a href="#cb53-43" aria-hidden="true" tabindex="-1"></a>train_loss <span class="op">=</span> losses.DenoisingAutoEncoderLoss(embedding_model, tie_encoder_decoder<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb53-44"><a href="#cb53-44" aria-hidden="true" tabindex="-1"></a>train_loss.decoder <span class="op">=</span> train_loss.decoder.to(<span class="st">"cuda"</span>)</span>
<span id="cb53-45"><a href="#cb53-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-46"><a href="#cb53-46" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 인자 정의</span></span>
<span id="cb53-47"><a href="#cb53-47" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> SentenceTransformerTrainingArguments(</span>
<span id="cb53-48"><a href="#cb53-48" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"tsdae_embedding_model"</span>,</span>
<span id="cb53-49"><a href="#cb53-49" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb53-50"><a href="#cb53-50" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb53-51"><a href="#cb53-51" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb53-52"><a href="#cb53-52" aria-hidden="true" tabindex="-1"></a>    warmup_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb53-53"><a href="#cb53-53" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-54"><a href="#cb53-54" aria-hidden="true" tabindex="-1"></a>    eval_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb53-55"><a href="#cb53-55" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb53-56"><a href="#cb53-56" aria-hidden="true" tabindex="-1"></a>    disable_tqdm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb53-57"><a href="#cb53-57" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-58"><a href="#cb53-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-59"><a href="#cb53-59" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 훈련</span></span>
<span id="cb53-60"><a href="#cb53-60" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> SentenceTransformerTrainer(</span>
<span id="cb53-61"><a href="#cb53-61" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>embedding_model,</span>
<span id="cb53-62"><a href="#cb53-62" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>args,</span>
<span id="cb53-63"><a href="#cb53-63" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb53-64"><a href="#cb53-64" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span>train_loss,</span>
<span id="cb53-65"><a href="#cb53-65" aria-hidden="true" tabindex="-1"></a>    evaluator<span class="op">=</span>evaluator,</span>
<span id="cb53-66"><a href="#cb53-66" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb53-67"><a href="#cb53-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-68"><a href="#cb53-68" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb53-69"><a href="#cb53-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-70"><a href="#cb53-70" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련된 모델 평가</span></span>
<span id="cb53-71"><a href="#cb53-71" aria-hidden="true" tabindex="-1"></a>evaluator(embedding_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt to /home/fkt/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt_tab to /home/fkt/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
100%|█████████████████████| 48353/48353 [00:03&lt;00:00, 15391.05it/s]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
      
      <progress value="3023" max="3023" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [3023/3023 02:42, Epoch 1/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1000</td>
<td>4.637300</td>
</tr>
<tr class="even">
<td>2000</td>
<td>3.883400</td>
</tr>
<tr class="odd">
<td>3000</td>
<td>3.647900</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ceec1d3857784c0aac1eb569554d70d8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>{'pearson_cosine': np.float64(0.7401165281596465),
 'spearman_cosine': np.float64(0.7469963144425136)}</code></pre>
</div>
</div>
<div id="bfce2153-8521-48ed-9bf7-31de741185e0" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># VRAM clean up</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>gc.collect()</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="분류를-위한-표현-모델-미세-조정" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="분류를-위한-표현-모델-미세-조정"><span class="header-section-number">3.2</span> 분류를 위한 표현 모델 미세 조정</h2>
<p>BERT 모델을 미세 조정하는 여러 방법과 응용 사례를 살펴보겠습니다.</p>
<section id="지도-학습-분류" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="지도-학습-분류"><span class="header-section-number">3.2.1</span> 지도 학습 분류</h3>
<p>사전 학습된 BERT 모델 미세 조정하기위해 앞서 사용했던 것과 동일한 Rotten Tomatoes 데이터셋을 활용하겠습니다. 영어 위키피디아와 미출판 도서들로 구성된 대규모 데이터셋으로 사전 학습된 “bert-base-cased” 모델을 사용할 것입니다.</p>
<div id="51dbc779-00a9-4369-a2c6-88ced843db8d" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evaluate</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    AutoModelForSequenceClassification,</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    DataCollatorWithPadding,</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    Trainer,</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    TrainingArguments,</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>    logging,</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>logging.set_verbosity_error()  <span class="co"># 경고 메시지가 표시되지 않고 오류 메시지만 표시</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)  <span class="co"># 경고 메시지 끄기</span></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터 준비 및 분할</span></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>tomatoes <span class="op">=</span> load_dataset(<span class="st">"rotten_tomatoes"</span>)</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>train_data, test_data <span class="op">=</span> tomatoes[<span class="st">"train"</span>], tomatoes[<span class="st">"test"</span>]</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 및 토크나이저 로드</span></span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"bert-base-cased"</span></span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_id, num_labels<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 배치 내 가장 긴 시퀀스에 맞춰 패딩</span></span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_function(examples):</span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""입력 데이터 토큰화"""</span></span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">"text"</span>], truncation<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a><span class="co"># 학습/테스트 데이터 토큰화</span></span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a>tokenized_train <span class="op">=</span> train_data.<span class="bu">map</span>(preprocess_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a>tokenized_test <span class="op">=</span> test_data.<span class="bu">map</span>(preprocess_function, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred):</span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate F1 score"""</span></span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a>    logits, labels <span class="op">=</span> eval_pred</span>
<span id="cb57-44"><a href="#cb57-44" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(logits, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb57-45"><a href="#cb57-45" aria-hidden="true" tabindex="-1"></a>    load_f1 <span class="op">=</span> evaluate.load(<span class="st">"f1"</span>)</span>
<span id="cb57-46"><a href="#cb57-46" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> load_f1.compute(predictions<span class="op">=</span>predictions, references<span class="op">=</span>labels)[<span class="st">"f1"</span>]</span>
<span id="cb57-47"><a href="#cb57-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"f1"</span>: f1}</span>
<span id="cb57-48"><a href="#cb57-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-49"><a href="#cb57-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-50"><a href="#cb57-50" aria-hidden="true" tabindex="-1"></a><span class="co"># 매개변수 튜닝을 위한 학습 인자</span></span>
<span id="cb57-51"><a href="#cb57-51" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb57-52"><a href="#cb57-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">"model"</span>,</span>
<span id="cb57-53"><a href="#cb57-53" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb57-54"><a href="#cb57-54" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb57-55"><a href="#cb57-55" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb57-56"><a href="#cb57-56" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb57-57"><a href="#cb57-57" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb57-58"><a href="#cb57-58" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb57-59"><a href="#cb57-59" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb57-60"><a href="#cb57-60" aria-hidden="true" tabindex="-1"></a>    disable_tqdm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb57-61"><a href="#cb57-61" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-62"><a href="#cb57-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-63"><a href="#cb57-63" aria-hidden="true" tabindex="-1"></a><span class="co"># 학습 과정을 실행하는 Trainer</span></span>
<span id="cb57-64"><a href="#cb57-64" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb57-65"><a href="#cb57-65" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb57-66"><a href="#cb57-66" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb57-67"><a href="#cb57-67" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_train,</span>
<span id="cb57-68"><a href="#cb57-68" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_test,</span>
<span id="cb57-69"><a href="#cb57-69" aria-hidden="true" tabindex="-1"></a>    processing_class<span class="op">=</span>tokenizer,</span>
<span id="cb57-70"><a href="#cb57-70" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb57-71"><a href="#cb57-71" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb57-72"><a href="#cb57-72" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-73"><a href="#cb57-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-74"><a href="#cb57-74" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 학습</span></span>
<span id="cb57-75"><a href="#cb57-75" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb57-76"><a href="#cb57-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-77"><a href="#cb57-77" aria-hidden="true" tabindex="-1"></a><span class="co"># 결과 평가</span></span>
<span id="cb57-78"><a href="#cb57-78" aria-hidden="true" tabindex="-1"></a>trainer.evaluate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
      
      <progress value="5340" max="5340" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [5340/5340 02:46, Epoch 10/10]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>500</td>
<td>0.418000</td>
</tr>
<tr class="even">
<td>1000</td>
<td>0.234400</td>
</tr>
<tr class="odd">
<td>1500</td>
<td>0.137900</td>
</tr>
<tr class="even">
<td>2000</td>
<td>0.072600</td>
</tr>
<tr class="odd">
<td>2500</td>
<td>0.038000</td>
</tr>
<tr class="even">
<td>3000</td>
<td>0.032400</td>
</tr>
<tr class="odd">
<td>3500</td>
<td>0.023500</td>
</tr>
<tr class="even">
<td>4000</td>
<td>0.007000</td>
</tr>
<tr class="odd">
<td>4500</td>
<td>0.010100</td>
</tr>
<tr class="even">
<td>5000</td>
<td>0.004100</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="67" max="67" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [67/67 00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>{'eval_loss': 1.279144048690796,
 'eval_f1': 0.8457899716177862,
 'eval_runtime': 1.4511,
 'eval_samples_per_second': 734.612,
 'eval_steps_per_second': 46.172,
 'epoch': 10.0}</code></pre>
</div>
</div>
</section>
<section id="적은-샷few-shot-분류" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="적은-샷few-shot-분류"><span class="header-section-number">3.2.2</span> 적은 샷(Few shot) 분류</h3>
<p>적은 샷 분류는 지도 학습 분류의 한 기법으로, 소수의 레이블된 예시만을 바탕으로 분류기가 목표 레이블을 학습하는 방법입니다. 이 기법은 분류 작업이 필요하지만 충분한 레이블된 데이터를 즉시 사용할 수 없을 때 유용합니다. 다시 말해, 이 방법을 통해 각 클래스당 소수의 고품질 데이터 포인트만 레이블링하여 모델을 훈련시킬 수 있습니다.</p>
<section id="setfit-적은-훈련-예시로-효율적인-미세-조정" class="level4" data-number="3.2.2.1">
<h4 data-number="3.2.2.1" class="anchored" data-anchor-id="setfit-적은-훈련-예시로-효율적인-미세-조정"><span class="header-section-number">3.2.2.1</span> SetFit: 적은 훈련 예시로 효율적인 미세 조정</h4>
<p>적은 샷 텍스트 분류를 수행하기 위해 SetFit이라는 효율적인 프레임워크를 사용합니다. 이는 문장 트랜스포머의 구조를 기반으로 하여 훈련 중 업데이트되는 고품질 텍스트 표현을 생성합니다. SetFit은 다음 세 단계로 구성됩니다: 1. 훈련 데이터 샘플링: 클래스 내부와 외부 선택을 기반으로 긍정적(유사한) 및 부정적(다른) 문장 쌍을 생성합니다. 2. 임베딩 미세 조정: 이전에 생성된 훈련 데이터를 바탕으로 사전 학습된 임베딩 모델을 미세 조정합니다. 3. 분류기 훈련: 임베딩 모델 위에 분류 헤드를 만들고 이전에 생성된 훈련 데이터를 사용하여 훈련시킵니다.</p>
</section>
<section id="적은-샷-분류를-위한-미세-조정" class="level4" data-number="3.2.2.2">
<h4 data-number="3.2.2.2" class="anchored" data-anchor-id="적은-샷-분류를-위한-미세-조정"><span class="header-section-number">3.2.2.2</span> 적은 샷 분류를 위한 미세 조정</h4>
<p>이전에는 약 8,500개의 영화 리뷰를 포함한 데이터셋으로 훈련했습니다. 하지만 이번에는 적은 샷 설정이므로 각 클래스당 16개의 예시만 샘플링할 것입니다. 두 개의 클래스가 있으므로 이전에 사용했던 8,500개의 영화 리뷰와 비교해 단 32개의 문서로만 훈련하게 됩니다.</p>
<div id="819c8131-c059-4781-a6ee-342e40e83fa9" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> setfit <span class="im">import</span> SetFitModel, sample_dataset</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> setfit <span class="im">import</span> Trainer <span class="im">as</span> SetFitTrainer</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> setfit <span class="im">import</span> TrainingArguments <span class="im">as</span> SetFitTrainingArguments</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 클래스당 16개의 예시를 샘플링하여 few-shot 설정을 시뮬레이션합니다</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>sampled_train_data <span class="op">=</span> sample_dataset(tomatoes[<span class="st">"train"</span>], num_samples<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 사전 훈련된 SentenceTransformer 모델을 로드합니다</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SetFitModel.from_pretrained(<span class="st">"sentence-transformers/all-mpnet-base-v2"</span>)</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 인자를 정의합니다</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span> SetFitTrainingArguments(</span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>    num_epochs<span class="op">=</span><span class="dv">3</span>,  <span class="co"># 대조 학습에 사용할 에폭 수</span></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>    num_iterations<span class="op">=</span><span class="dv">20</span>,  <span class="co"># 생성할 텍스트 쌍의 수</span></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>args.eval_strategy <span class="op">=</span> args.evaluation_strategy</span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 트레이너를 생성합니다</span></span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> SetFitTrainer(</span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>args,</span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>sampled_train_data,</span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>test_data,</span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a>    metric<span class="op">=</span><span class="st">"f1"</span>,</span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 루프</span></span>
<span id="cb59-28"><a href="#cb59-28" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb59-29"><a href="#cb59-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-30"><a href="#cb59-30" aria-hidden="true" tabindex="-1"></a><span class="co"># 테스트 데이터로 모델을 평가합니다</span></span>
<span id="cb59-31"><a href="#cb59-31" aria-hidden="true" tabindex="-1"></a>trainer.evaluate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"24b020d35aee4bc3b68fad0a662517ab","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running training *****
  Num unique pairs = 1280
  Batch size = 16
  Num epochs = 3</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'embedding_loss': 0.3226, 'grad_norm': 1.9545438289642334, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.0125}
{'embedding_loss': 0.1147, 'grad_norm': 0.20879538357257843, 'learning_rate': 1.7592592592592595e-05, 'epoch': 0.625}
{'embedding_loss': 0.0009, 'grad_norm': 0.026085715740919113, 'learning_rate': 1.2962962962962964e-05, 'epoch': 1.25}
{'embedding_loss': 0.0004, 'grad_norm': 0.016781330108642578, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.875}
{'embedding_loss': 0.0003, 'grad_norm': 0.011119991540908813, 'learning_rate': 3.7037037037037037e-06, 'epoch': 2.5}</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3734eb3a74714de8861ac0808da45d83","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>***** Running evaluation *****</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'train_runtime': 13.0872, 'train_samples_per_second': 293.417, 'train_steps_per_second': 18.339, 'train_loss': 0.025163489832387618, 'epoch': 3.0}</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>{'f1': 0.8462273161413563}</code></pre>
</div>
</div>
<p>32개의 레이블된 문서만으로 약 0.85의 F1 점수를 얻었습니다. 원본 데이터의 아주 작은 부분집합으로만 모델을 훈련시켰다는 점을 고려하면 이는 매우 인상적인 결과입니다! SetFit은 적은 샷 분류 작업을 수행할 수 있을 뿐만 아니라 레이블이 전혀 없는 경우인 제로샷 분류에도 대응할 수 있습니다.</p>
</section>
</section>
</section>
<section id="생성-모델-미세-조정" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="생성-모델-미세-조정"><span class="header-section-number">3.3</span> 생성 모델 미세 조정</h2>
<section id="지도-학습-미세-조정-sft" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="지도-학습-미세-조정-sft"><span class="header-section-number">3.3.1</span> 지도 학습 미세 조정 (SFT)</h3>
<section id="전체-미세-조정" class="level4" data-number="3.3.1.1">
<h4 data-number="3.3.1.1" class="anchored" data-anchor-id="전체-미세-조정"><span class="header-section-number">3.3.1.1</span> 전체 미세 조정</h4>
<p>가장 일반적인 미세 조정 과정은 전체 미세 조정입니다. LLM을 사전 학습하는 것과 마찬가지로, 이 과정은 목표로 하는 지도 학습 미세 조정(SFT) 작업에 맞춰 모델의 모든 매개변수를 업데이트하는 것을 포함합니다.</p>
</section>
<section id="매개변수-효율적-미세-조정-peft" class="level4" data-number="3.3.1.2">
<h4 data-number="3.3.1.2" class="anchored" data-anchor-id="매개변수-효율적-미세-조정-peft"><span class="header-section-number">3.3.1.2</span> 매개변수 효율적 미세 조정 (PEFT)</h4>
<p>모델의 모든 매개변수를 업데이트하는 것은 성능을 크게 향상시킬 수 있는 잠재력이 있지만 몇 가지 단점이 있습니다. 훈련 비용이 많이 들고, 훈련 시간이 길며, 상당한 저장 공간이 필요합니다. 이러한 문제를 해결하기 위해, 더 높은 계산 효율성으로 사전 학습된 모델을 미세 조정하는 데 중점을 둔 매개변수 효율적 미세 조정(PEFT) 대안에 관심이 모아지고 있습니다.</p>
<section id="어댑터" class="level5" data-number="3.3.1.2.1">
<h5 data-number="3.3.1.2.1" class="anchored" data-anchor-id="어댑터"><span class="header-section-number">3.3.1.2.1</span> 어댑터</h5>
<p>어댑터는 많은 PEFT 기반 기술의 핵심 구성 요소입니다. 이 방법은 트랜스포머 내부에 추가적인 모듈식 구성 요소를 제안하며, 이를 미세 조정하여 모델의 모든 가중치를 미세 조정할 필요 없이 특정 작업에 대한 모델의 성능을 향상시킬 수 있습니다. 이는 많은 시간과 계산 자원을 절약합니다.</p>
</section>
<section id="저순위-적응-lora" class="level5" data-number="3.3.1.2.2">
<h5 data-number="3.3.1.2.2" class="anchored" data-anchor-id="저순위-적응-lora"><span class="header-section-number">3.3.1.2.2</span> 저순위 적응 (LoRA)</h5>
<p>어댑터의 대안으로, 저순위 적응(LoRA)이 소개되었으며 현재 PEFT를 위한 널리 사용되고 효과적인 기술입니다. LoRA는 (어댑터와 마찬가지로) 작은 수의 매개변수만 업데이트하면 되는 기술입니다.</p>
<blockquote class="blockquote">
<p>더 효율적인 훈련을 위한 모델 압축: LoRA를 더욱 효율적으로 만들기 위해 원래 가중치를 더 작은 행렬로 투영하기 전에 모델의 원래 가중치의 메모리 요구 사항을 줄일 수 있습니다. LLM의 가중치는 float64나 float32와 같은 비트 수로 표현될 수 있는 주어진 정밀도를 가진 숫자 값입니다.</p>
</blockquote>
<div id="3058b119-6fe5-4b8b-a352-935ea7bf3d8e" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> LoraConfig, get_peft_model, prepare_model_for_kbit_training</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>    AutoModelForCausalLM,</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>    AutoTokenizer,</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    BitsAndBytesConfig,</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>    TrainingArguments,</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trl <span class="im">import</span> SFTTrainer</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">"./model"</span></span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a><span class="co"># TinyLlama의 채팅 템플릿을 사용하기 위해 토크나이저 로드</span></span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>template_tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span>)</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_prompt(example):</span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""TinyLLama가 사용하는 &lt;|user|&gt; 템플릿을 사용하여 프롬프트 포맷"""</span></span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 답변 포맷</span></span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>    chat <span class="op">=</span> example[<span class="st">"messages"</span>]</span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> template_tokenizer.apply_chat_template(chat, tokenize<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"text"</span>: prompt}</span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a><span class="co"># TinyLLama가 사용하는 템플릿을 사용하여 데이터 로드 및 포맷</span></span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> (</span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a>    load_dataset(<span class="st">"HuggingFaceH4/ultrachat_200k"</span>, split<span class="op">=</span><span class="st">"test_sft"</span>)</span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a>    .shuffle(seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a>    .select(<span class="bu">range</span>(<span class="dv">3_000</span>))</span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-34"><a href="#cb66-34" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.<span class="bu">map</span>(format_prompt)</span>
<span id="cb66-35"><a href="#cb66-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-36"><a href="#cb66-36" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T"</span></span>
<span id="cb66-37"><a href="#cb66-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-38"><a href="#cb66-38" aria-hidden="true" tabindex="-1"></a><span class="co"># 4비트 양자화 설정 - QLoRA의 Q</span></span>
<span id="cb66-39"><a href="#cb66-39" aria-hidden="true" tabindex="-1"></a>bnb_config <span class="op">=</span> BitsAndBytesConfig(</span>
<span id="cb66-40"><a href="#cb66-40" aria-hidden="true" tabindex="-1"></a>    load_in_4bit<span class="op">=</span><span class="va">True</span>,  <span class="co"># 4비트 정밀도 모델 로딩 사용</span></span>
<span id="cb66-41"><a href="#cb66-41" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_quant_type<span class="op">=</span><span class="st">"nf4"</span>,  <span class="co"># 양자화 유형</span></span>
<span id="cb66-42"><a href="#cb66-42" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_compute_dtype<span class="op">=</span><span class="st">"float16"</span>,  <span class="co"># 계산 데이터 타입</span></span>
<span id="cb66-43"><a href="#cb66-43" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_use_double_quant<span class="op">=</span><span class="va">True</span>,  <span class="co"># 중첩 양자화 적용</span></span>
<span id="cb66-44"><a href="#cb66-44" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-45"><a href="#cb66-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-46"><a href="#cb66-46" aria-hidden="true" tabindex="-1"></a><span class="co"># GPU에서 훈련할 모델 로드</span></span>
<span id="cb66-47"><a href="#cb66-47" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb66-48"><a href="#cb66-48" aria-hidden="true" tabindex="-1"></a>    model_name,</span>
<span id="cb66-49"><a href="#cb66-49" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb66-50"><a href="#cb66-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 일반 SFT의 경우 이 부분 제외</span></span>
<span id="cb66-51"><a href="#cb66-51" aria-hidden="true" tabindex="-1"></a>    quantization_config<span class="op">=</span>bnb_config,</span>
<span id="cb66-52"><a href="#cb66-52" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-53"><a href="#cb66-53" aria-hidden="true" tabindex="-1"></a>model.config.use_cache <span class="op">=</span> <span class="va">False</span></span>
<span id="cb66-54"><a href="#cb66-54" aria-hidden="true" tabindex="-1"></a>model.config.pretraining_tp <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb66-55"><a href="#cb66-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-56"><a href="#cb66-56" aria-hidden="true" tabindex="-1"></a><span class="co"># LLaMA 토크나이저 로드</span></span>
<span id="cb66-57"><a href="#cb66-57" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb66-58"><a href="#cb66-58" aria-hidden="true" tabindex="-1"></a>tokenizer.pad_token <span class="op">=</span> <span class="st">"&lt;PAD&gt;"</span></span>
<span id="cb66-59"><a href="#cb66-59" aria-hidden="true" tabindex="-1"></a>tokenizer.padding_side <span class="op">=</span> <span class="st">"left"</span></span>
<span id="cb66-60"><a href="#cb66-60" aria-hidden="true" tabindex="-1"></a>tokenizer.chat_template <span class="op">=</span> template_tokenizer.chat_template</span>
<span id="cb66-61"><a href="#cb66-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-62"><a href="#cb66-62" aria-hidden="true" tabindex="-1"></a><span class="co"># LoRA 설정 준비</span></span>
<span id="cb66-63"><a href="#cb66-63" aria-hidden="true" tabindex="-1"></a>peft_config <span class="op">=</span> LoraConfig(</span>
<span id="cb66-64"><a href="#cb66-64" aria-hidden="true" tabindex="-1"></a>    lora_alpha<span class="op">=</span><span class="dv">32</span>,  <span class="co"># LoRA 스케일링</span></span>
<span id="cb66-65"><a href="#cb66-65" aria-hidden="true" tabindex="-1"></a>    lora_dropout<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># LoRA 레이어의 드롭아웃</span></span>
<span id="cb66-66"><a href="#cb66-66" aria-hidden="true" tabindex="-1"></a>    r<span class="op">=</span><span class="dv">64</span>,  <span class="co"># 랭크</span></span>
<span id="cb66-67"><a href="#cb66-67" aria-hidden="true" tabindex="-1"></a>    bias<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb66-68"><a href="#cb66-68" aria-hidden="true" tabindex="-1"></a>    task_type<span class="op">=</span><span class="st">"CAUSAL_LM"</span>,</span>
<span id="cb66-69"><a href="#cb66-69" aria-hidden="true" tabindex="-1"></a>    target_modules<span class="op">=</span>[  <span class="co"># 대상 레이어</span></span>
<span id="cb66-70"><a href="#cb66-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">"k_proj"</span>,</span>
<span id="cb66-71"><a href="#cb66-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">"gate_proj"</span>,</span>
<span id="cb66-72"><a href="#cb66-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">"v_proj"</span>,</span>
<span id="cb66-73"><a href="#cb66-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">"up_proj"</span>,</span>
<span id="cb66-74"><a href="#cb66-74" aria-hidden="true" tabindex="-1"></a>        <span class="st">"q_proj"</span>,</span>
<span id="cb66-75"><a href="#cb66-75" aria-hidden="true" tabindex="-1"></a>        <span class="st">"o_proj"</span>,</span>
<span id="cb66-76"><a href="#cb66-76" aria-hidden="true" tabindex="-1"></a>        <span class="st">"down_proj"</span>,</span>
<span id="cb66-77"><a href="#cb66-77" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb66-78"><a href="#cb66-78" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-79"><a href="#cb66-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-80"><a href="#cb66-80" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련을 위한 모델 준비</span></span>
<span id="cb66-81"><a href="#cb66-81" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> prepare_model_for_kbit_training(model)</span>
<span id="cb66-82"><a href="#cb66-82" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> get_peft_model(model, peft_config)</span>
<span id="cb66-83"><a href="#cb66-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-84"><a href="#cb66-84" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 인자</span></span>
<span id="cb66-85"><a href="#cb66-85" aria-hidden="true" tabindex="-1"></a>training_arguments <span class="op">=</span> TrainingArguments(</span>
<span id="cb66-86"><a href="#cb66-86" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>output_dir,</span>
<span id="cb66-87"><a href="#cb66-87" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb66-88"><a href="#cb66-88" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb66-89"><a href="#cb66-89" aria-hidden="true" tabindex="-1"></a>    optim<span class="op">=</span><span class="st">"paged_adamw_32bit"</span>,</span>
<span id="cb66-90"><a href="#cb66-90" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-4</span>,</span>
<span id="cb66-91"><a href="#cb66-91" aria-hidden="true" tabindex="-1"></a>    lr_scheduler_type<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb66-92"><a href="#cb66-92" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb66-93"><a href="#cb66-93" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb66-94"><a href="#cb66-94" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb66-95"><a href="#cb66-95" aria-hidden="true" tabindex="-1"></a>    gradient_checkpointing<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb66-96"><a href="#cb66-96" aria-hidden="true" tabindex="-1"></a>    disable_tqdm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb66-97"><a href="#cb66-97" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-98"><a href="#cb66-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-99"><a href="#cb66-99" aria-hidden="true" tabindex="-1"></a><span class="co"># 지도 미세조정 매개변수 설정</span></span>
<span id="cb66-100"><a href="#cb66-100" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> SFTTrainer(</span>
<span id="cb66-101"><a href="#cb66-101" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb66-102"><a href="#cb66-102" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>dataset,</span>
<span id="cb66-103"><a href="#cb66-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># dataset_text_field="text",</span></span>
<span id="cb66-104"><a href="#cb66-104" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb66-105"><a href="#cb66-105" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_arguments,</span>
<span id="cb66-106"><a href="#cb66-106" aria-hidden="true" tabindex="-1"></a>    <span class="co"># max_seq_length=512,</span></span>
<span id="cb66-107"><a href="#cb66-107" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 일반 SFT의 경우 이 부분 제외</span></span>
<span id="cb66-108"><a href="#cb66-108" aria-hidden="true" tabindex="-1"></a>    peft_config<span class="op">=</span>peft_config,</span>
<span id="cb66-109"><a href="#cb66-109" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb66-110"><a href="#cb66-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-111"><a href="#cb66-111" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 훈련</span></span>
<span id="cb66-112"><a href="#cb66-112" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb66-113"><a href="#cb66-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-114"><a href="#cb66-114" aria-hidden="true" tabindex="-1"></a><span class="co"># QLoRA 가중치 저장</span></span>
<span id="cb66-115"><a href="#cb66-115" aria-hidden="true" tabindex="-1"></a>trainer.model.save_pretrained(<span class="st">"./model/TinyLlama-1.1B-qlora"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
      
      <progress value="375" max="375" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [375/375 06:35, Epoch 1/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100</td>
<td>5.425600</td>
</tr>
<tr class="even">
<td>200</td>
<td>5.160700</td>
</tr>
<tr class="odd">
<td>300</td>
<td>5.117600</td>
</tr>
</tbody>
</table>
<p>
</p></div>
</div>
<div id="9f5b495b-71c9-4227-a1d9-eb80933cdf94" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> AutoPeftModelForCausalLM</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoPeftModelForCausalLM.from_pretrained(</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"./model/TinyLlama-1.1B-qlora"</span>,</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>    low_cpu_mem_usage<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a><span class="co"># LoRA와 기본 모델 병합</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>merged_model <span class="op">=</span> model.merge_and_unload()</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 미리 정의된 프롬프트 템플릿 사용</span></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"""&lt;|user|&gt;</span></span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="st">독감 예방 접종이 필요한 이유에 대해 간단히 설명해줘.&lt;/s&gt;</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;|assistant|&gt;</span></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 튜닝된 모델 실행</span></span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-generation"</span>, model<span class="op">=</span>merged_model, tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>pipe(prompt)[<span class="dv">0</span>][<span class="st">"generated_text"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>'&lt;|user|&gt;\n독감 예방 접종이 필요한 이유에 대해 간단히 설명해줘.&lt;/s&gt;\n&lt;|assistant|&gt;\nThe reason for preventive treatment is to prevent the spread of the disease and to reduce the risk of complications. This is especially important for people with underlying health conditions, such as diabetes or high blood pressure, who are at higher risk of developing complications.'</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="생성-모델-평가" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="생성-모델-평가"><span class="header-section-number">3.3.2</span> 생성 모델 평가</h3>
<p>생성 모델을 평가하는 것은 상당한 도전 과제입니다.</p>
<section id="단어-수준-지표" class="level4" data-number="3.3.2.1">
<h4 data-number="3.3.2.1" class="anchored" data-anchor-id="단어-수준-지표"><span class="header-section-number">3.3.2.1</span> 단어 수준 지표</h4>
<p>생성 모델을 비교하는 데 흔히 사용되는 지표 범주 중 하나는 단어 수준 평가입니다. 이러한 전통적인 기법들은 참조 데이터셋과 생성된 토큰을 토큰(집합) 수준에서 비교합니다. 일반적인 단어 수준 지표로는 혼란도(perplexity), ROUGE, BLEU, BERTScore 등이 있습니다.</p>
</section>
<section id="벤치마크" class="level4" data-number="3.3.2.2">
<h4 data-number="3.3.2.2" class="anchored" data-anchor-id="벤치마크"><span class="header-section-number">3.3.2.2</span> 벤치마크</h4>
<p>언어 생성 및 이해 작업에 대한 생성 모델을 평가하는 일반적인 방법은 MMLU, GLUE, TruthfulQA, GSM8k, HellaSwag와 같은 잘 알려진 공개 벤치마크를 사용하는 것입니다.</p>
</section>
<section id="리더보드" class="level4" data-number="3.3.2.3">
<h4 data-number="3.3.2.3" class="anchored" data-anchor-id="리더보드"><span class="header-section-number">3.3.2.3</span> 리더보드</h4>
<p>다양한 벤치마크가 존재하기 때문에 어떤 벤치마크가 자신의 모델에 가장 적합한지 선택하기 어려울 수 있습니다. 모델이 공개될 때마다 여러 벤치마크에서 평가되어 전반적인 성능을 보여주는 경우가 많습니다.</p>
<p>이에 따라 여러 벤치마크를 포함하는 리더보드가 개발되었습니다. 일반적인 리더보드로는 Open LLM Leaderboard가 있으며, 현재 HellaSwag, MMLU, TruthfulQA, GSM8k 등 6개의 벤치마크를 포함하고 있습니다.</p>
</section>
</section>
<section id="선호도-튜닝-ppodpo" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="선호도-튜닝-ppodpo"><span class="header-section-number">3.3.3</span> 선호도 튜닝 (PPO/DPO)</h3>
<p>모델이 지시를 따를 수 있게 되었더라도, 다양한 상황에서 우리가 기대하는 대로 행동하도록 최종 훈련 단계를 통해 더욱 개선할 수 있습니다. 예를 들어, “LLM이란 무엇인가요?”라는 질문에 대해 “대규모 언어 모델입니다”라는 간단한 답변보다는 LLM의 내부 구조를 자세히 설명하는 답변을 선호할 수 있습니다. 그렇다면 어떻게 하나의 답변을 다른 답변보다 선호하는 우리의 (인간의) 선호도를 LLM의 출력과 일치시킬 수 있을까요?</p>
<div id="35944231-bb54-4782-8eb3-d92e83987e4d" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> (</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    AutoPeftModelForCausalLM,</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    LoraConfig,</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    get_peft_model,</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    prepare_model_for_kbit_training,</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, BitsAndBytesConfig, logging</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trl <span class="im">import</span> DPOConfig, DPOTrainer</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터 전처리</span></span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_prompt(example):</span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""TinyLLama가 사용하는 &lt;|user|&gt; 템플릿을 사용하여 프롬프트 포맷"""</span></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>    system <span class="op">=</span> <span class="st">"&lt;|system|&gt;</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> example[<span class="st">"system"</span>] <span class="op">+</span> <span class="st">"&lt;/s&gt;</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="st">"&lt;|user|&gt;</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> example[<span class="st">"input"</span>] <span class="op">+</span> <span class="st">"&lt;/s&gt;</span><span class="ch">\n</span><span class="st">&lt;|assistant|&gt;</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>    chosen <span class="op">=</span> example[<span class="st">"chosen"</span>] <span class="op">+</span> <span class="st">"&lt;/s&gt;</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>    rejected <span class="op">=</span> example[<span class="st">"rejected"</span>] <span class="op">+</span> <span class="st">"&lt;/s&gt;</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"prompt"</span>: system <span class="op">+</span> prompt,</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"chosen"</span>: chosen,</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"rejected"</span>: rejected,</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터셋에 포맷 적용 및 비교적 짧은 답변 선택</span></span>
<span id="cb69-27"><a href="#cb69-27" aria-hidden="true" tabindex="-1"></a>dpo_dataset <span class="op">=</span> load_dataset(<span class="st">"argilla/distilabel-intel-orca-dpo-pairs"</span>, split<span class="op">=</span><span class="st">"train"</span>)</span>
<span id="cb69-28"><a href="#cb69-28" aria-hidden="true" tabindex="-1"></a>dpo_dataset <span class="op">=</span> dpo_dataset.<span class="bu">filter</span>(</span>
<span id="cb69-29"><a href="#cb69-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> r: r[<span class="st">"status"</span>] <span class="op">!=</span> <span class="st">"tie"</span> <span class="kw">and</span> r[<span class="st">"chosen_score"</span>] <span class="op">&gt;=</span> <span class="dv">8</span> <span class="kw">and</span> <span class="kw">not</span> r[<span class="st">"in_gsm8k_train"</span>]</span>
<span id="cb69-30"><a href="#cb69-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-31"><a href="#cb69-31" aria-hidden="true" tabindex="-1"></a>dpo_dataset <span class="op">=</span> dpo_dataset.<span class="bu">map</span>(format_prompt, remove_columns<span class="op">=</span>dpo_dataset.column_names)</span>
<span id="cb69-32"><a href="#cb69-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-33"><a href="#cb69-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 양자화</span></span>
<span id="cb69-34"><a href="#cb69-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 4비트 양자화 설정 - QLoRA의 Q</span></span>
<span id="cb69-35"><a href="#cb69-35" aria-hidden="true" tabindex="-1"></a>bnb_config <span class="op">=</span> BitsAndBytesConfig(</span>
<span id="cb69-36"><a href="#cb69-36" aria-hidden="true" tabindex="-1"></a>    load_in_4bit<span class="op">=</span><span class="va">True</span>,  <span class="co"># 4비트 정밀도 모델 로딩 사용</span></span>
<span id="cb69-37"><a href="#cb69-37" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_quant_type<span class="op">=</span><span class="st">"nf4"</span>,  <span class="co"># 양자화 타입</span></span>
<span id="cb69-38"><a href="#cb69-38" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_compute_dtype<span class="op">=</span><span class="st">"float16"</span>,  <span class="co"># 계산 데이터 타입</span></span>
<span id="cb69-39"><a href="#cb69-39" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_use_double_quant<span class="op">=</span><span class="va">True</span>,  <span class="co"># 중첩 양자화 적용</span></span>
<span id="cb69-40"><a href="#cb69-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-41"><a href="#cb69-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-42"><a href="#cb69-42" aria-hidden="true" tabindex="-1"></a><span class="co"># LoRA와 기본 모델 병합</span></span>
<span id="cb69-43"><a href="#cb69-43" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoPeftModelForCausalLM.from_pretrained(</span>
<span id="cb69-44"><a href="#cb69-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">"./model/TinyLlama-1.1B-qlora"</span>,</span>
<span id="cb69-45"><a href="#cb69-45" aria-hidden="true" tabindex="-1"></a>    low_cpu_mem_usage<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb69-46"><a href="#cb69-46" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb69-47"><a href="#cb69-47" aria-hidden="true" tabindex="-1"></a>    quantization_config<span class="op">=</span>bnb_config,</span>
<span id="cb69-48"><a href="#cb69-48" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-49"><a href="#cb69-49" aria-hidden="true" tabindex="-1"></a>merged_model <span class="op">=</span> model.merge_and_unload()</span>
<span id="cb69-50"><a href="#cb69-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-51"><a href="#cb69-51" aria-hidden="true" tabindex="-1"></a><span class="co"># LLaMA 토크나이저 로드</span></span>
<span id="cb69-52"><a href="#cb69-52" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T"</span></span>
<span id="cb69-53"><a href="#cb69-53" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb69-54"><a href="#cb69-54" aria-hidden="true" tabindex="-1"></a>tokenizer.pad_token <span class="op">=</span> <span class="st">"&lt;PAD&gt;"</span></span>
<span id="cb69-55"><a href="#cb69-55" aria-hidden="true" tabindex="-1"></a>tokenizer.padding_side <span class="op">=</span> <span class="st">"left"</span></span>
<span id="cb69-56"><a href="#cb69-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-57"><a href="#cb69-57" aria-hidden="true" tabindex="-1"></a><span class="co"># LoRA 설정 준비</span></span>
<span id="cb69-58"><a href="#cb69-58" aria-hidden="true" tabindex="-1"></a>peft_config <span class="op">=</span> LoraConfig(</span>
<span id="cb69-59"><a href="#cb69-59" aria-hidden="true" tabindex="-1"></a>    lora_alpha<span class="op">=</span><span class="dv">32</span>,  <span class="co"># LoRA 스케일링</span></span>
<span id="cb69-60"><a href="#cb69-60" aria-hidden="true" tabindex="-1"></a>    lora_dropout<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># LoRA 레이어의 드롭아웃</span></span>
<span id="cb69-61"><a href="#cb69-61" aria-hidden="true" tabindex="-1"></a>    r<span class="op">=</span><span class="dv">64</span>,  <span class="co"># 랭크</span></span>
<span id="cb69-62"><a href="#cb69-62" aria-hidden="true" tabindex="-1"></a>    bias<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb69-63"><a href="#cb69-63" aria-hidden="true" tabindex="-1"></a>    task_type<span class="op">=</span><span class="st">"CAUSAL_LM"</span>,</span>
<span id="cb69-64"><a href="#cb69-64" aria-hidden="true" tabindex="-1"></a>    target_modules<span class="op">=</span>[</span>
<span id="cb69-65"><a href="#cb69-65" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 대상 레이어</span></span>
<span id="cb69-66"><a href="#cb69-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">"k_proj"</span>,</span>
<span id="cb69-67"><a href="#cb69-67" aria-hidden="true" tabindex="-1"></a>        <span class="st">"gate_proj"</span>,</span>
<span id="cb69-68"><a href="#cb69-68" aria-hidden="true" tabindex="-1"></a>        <span class="st">"v_proj"</span>,</span>
<span id="cb69-69"><a href="#cb69-69" aria-hidden="true" tabindex="-1"></a>        <span class="st">"up_proj"</span>,</span>
<span id="cb69-70"><a href="#cb69-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">"q_proj"</span>,</span>
<span id="cb69-71"><a href="#cb69-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">"o_proj"</span>,</span>
<span id="cb69-72"><a href="#cb69-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">"down_proj"</span>,</span>
<span id="cb69-73"><a href="#cb69-73" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb69-74"><a href="#cb69-74" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-75"><a href="#cb69-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-76"><a href="#cb69-76" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련을 위한 모델 준비</span></span>
<span id="cb69-77"><a href="#cb69-77" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> prepare_model_for_kbit_training(model)</span>
<span id="cb69-78"><a href="#cb69-78" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> get_peft_model(model, peft_config)</span>
<span id="cb69-79"><a href="#cb69-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-80"><a href="#cb69-80" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">"./model"</span></span>
<span id="cb69-81"><a href="#cb69-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-82"><a href="#cb69-82" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 인자</span></span>
<span id="cb69-83"><a href="#cb69-83" aria-hidden="true" tabindex="-1"></a>training_arguments <span class="op">=</span> DPOConfig(</span>
<span id="cb69-84"><a href="#cb69-84" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>output_dir,</span>
<span id="cb69-85"><a href="#cb69-85" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb69-86"><a href="#cb69-86" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb69-87"><a href="#cb69-87" aria-hidden="true" tabindex="-1"></a>    optim<span class="op">=</span><span class="st">"paged_adamw_32bit"</span>,</span>
<span id="cb69-88"><a href="#cb69-88" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">1e-5</span>,</span>
<span id="cb69-89"><a href="#cb69-89" aria-hidden="true" tabindex="-1"></a>    lr_scheduler_type<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb69-90"><a href="#cb69-90" aria-hidden="true" tabindex="-1"></a>    max_steps<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb69-91"><a href="#cb69-91" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb69-92"><a href="#cb69-92" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb69-93"><a href="#cb69-93" aria-hidden="true" tabindex="-1"></a>    gradient_checkpointing<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb69-94"><a href="#cb69-94" aria-hidden="true" tabindex="-1"></a>    warmup_ratio<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb69-95"><a href="#cb69-95" aria-hidden="true" tabindex="-1"></a>    beta<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># beta 값을 여기에 추가</span></span>
<span id="cb69-96"><a href="#cb69-96" aria-hidden="true" tabindex="-1"></a>    max_prompt_length<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb69-97"><a href="#cb69-97" aria-hidden="true" tabindex="-1"></a>    max_length<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb69-98"><a href="#cb69-98" aria-hidden="true" tabindex="-1"></a>    disable_tqdm<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb69-99"><a href="#cb69-99" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-100"><a href="#cb69-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-101"><a href="#cb69-101" aria-hidden="true" tabindex="-1"></a><span class="co"># DPO 트레이너 생성</span></span>
<span id="cb69-102"><a href="#cb69-102" aria-hidden="true" tabindex="-1"></a>dpo_trainer <span class="op">=</span> DPOTrainer(</span>
<span id="cb69-103"><a href="#cb69-103" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb69-104"><a href="#cb69-104" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_arguments,</span>
<span id="cb69-105"><a href="#cb69-105" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>dpo_dataset,</span>
<span id="cb69-106"><a href="#cb69-106" aria-hidden="true" tabindex="-1"></a>    processing_class<span class="op">=</span>tokenizer,  <span class="co"># tokenizer 대신 processing_class 사용</span></span>
<span id="cb69-107"><a href="#cb69-107" aria-hidden="true" tabindex="-1"></a>    peft_config<span class="op">=</span>peft_config,</span>
<span id="cb69-108"><a href="#cb69-108" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb69-109"><a href="#cb69-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-110"><a href="#cb69-110" aria-hidden="true" tabindex="-1"></a><span class="co"># DPO로 모델 미세조정</span></span>
<span id="cb69-111"><a href="#cb69-111" aria-hidden="true" tabindex="-1"></a>dpo_trainer.train()</span>
<span id="cb69-112"><a href="#cb69-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-113"><a href="#cb69-113" aria-hidden="true" tabindex="-1"></a><span class="co"># 어댑터 저장</span></span>
<span id="cb69-114"><a href="#cb69-114" aria-hidden="true" tabindex="-1"></a>dpo_trainer.model.save_pretrained(<span class="st">"./model/TinyLlama-1.1B-dpo-qlora"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
      
      <progress value="500" max="500" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [500/500 10:36, Epoch 0/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100</td>
<td>0.593300</td>
</tr>
<tr class="even">
<td>200</td>
<td>0.485700</td>
</tr>
<tr class="odd">
<td>300</td>
<td>0.520400</td>
</tr>
<tr class="even">
<td>400</td>
<td>0.476500</td>
</tr>
<tr class="odd">
<td>500</td>
<td>0.489200</td>
</tr>
</tbody>
</table>
<p>
</p></div>
</div>
<div id="82150d4a-2f63-4556-9c53-08c22de77930" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> PeftModel</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co"># LoRA와 기본 모델 병합</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoPeftModelForCausalLM.from_pretrained(</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"./model/TinyLlama-1.1B-qlora"</span>,</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    low_cpu_mem_usage<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>sft_model <span class="op">=</span> model.merge_and_unload()</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a><span class="co"># DPO LoRA와 SFT 모델 병합</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>dpo_model <span class="op">=</span> PeftModel.from_pretrained(</span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    sft_model,</span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"./model/TinyLlama-1.1B-dpo-qlora"</span>,</span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>dpo_model <span class="op">=</span> dpo_model.merge_and_unload()</span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 정의된 프롬프트 템플릿 사용</span></span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"""&lt;|user|&gt;</span></span>
<span id="cb70-22"><a href="#cb70-22" aria-hidden="true" tabindex="-1"></a><span class="st">독감 예방 접종의 중요성에 대해 설명해.&lt;/s&gt;</span></span>
<span id="cb70-23"><a href="#cb70-23" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;|assistant|&gt;</span></span>
<span id="cb70-24"><a href="#cb70-24" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb70-25"><a href="#cb70-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-26"><a href="#cb70-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 튜닝된 모델 실행</span></span>
<span id="cb70-27"><a href="#cb70-27" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-generation"</span>, model<span class="op">=</span>dpo_model, tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb70-28"><a href="#cb70-28" aria-hidden="true" tabindex="-1"></a>pipe(prompt)[<span class="dv">0</span>][<span class="st">"generated_text"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>'&lt;|user|&gt;\n독감 예방 접종의 중요성에 대해 설명해.&lt;/s&gt;\n&lt;|assistant|&gt;\nThe importance of preventive treatment in the prevention of chronic diseases has been recognized for centuries. Chronic diseases such as heart disease, stroke, diabetes, and cancer are the leading causes of death worldwide. Preventive treatment is essential to reduce the risk of developing these diseases and improve the quality of life for patients.\n\nPreventive treatment involves a combination of lifestyle changes, medications, and medical interventions. These interventions aim to reduce the risk of developing chronic diseases by modifying the lifestyle of the patient, such as smoking cessation, physical activity, and dietary modification.\n\nPreventive treatment is often recommended for patients with high risk of developing chronic diseases, such as those with a family history of heart disease, diabetes, or cancer. Patients with these risk factors should be screened regularly for early detection of the disease and receive preventive treatment as soon as possible.\n\nIn addition to preventive treatment, patients with chronic diseases should be monitored regularly to detect any changes in their condition and to ensure that they receive the appropriate treatment. This monitoring can help to identify early signs of disease progression and to prevent complications.\n\nIn conclusion, preventive treatment is essential to reduce the risk of developing chronic diseases and improve the quality of life for patients. By following a healthy lifestyle, making lifestyle changes, and receiving preventive treatment, patients can reduce their risk of developing chronic diseases and improve their overall health.'</code></pre>
</div>
</div>
<p>우리가 살펴본 미세 조정 과정은 두 단계로 이루어집니다. 첫 번째 단계에서는 사전 학습된 LLM에 지시 데이터를 사용하여 지도 학습 미세 조정을 수행했으며, 이를 흔히 지시 튜닝이라고 합니다. 이 결과로 채팅과 유사한 행동을 하고 지시를 정확히 따를 수 있는 모델이 만들어졌습니다.</p>
<p>두 번째 단계에서는 정렬 데이터, 즉 어떤 유형의 답변이 다른 답변보다 선호되는지를 나타내는 데이터로 모델을 더욱 개선했습니다. 선호도 튜닝이라고 불리는 이 과정은 이전에 지시 튜닝된 모델에 인간의 선호도를 주입합니다.</p>
<p>SFT+DPO의 조합을 통한 미세 조절은 훌륭한 방법이지만 두 번의 훈련 루프를 수행하고 두 과정에서 매개변수를 조정해야기 때문에 많은 계산 비용이 발생합니다. 이런 점을 극복하기 위해 새로운 방법들이 나오고 있는데 그 중에 주목할 만한 것은 Odds Ratio Preference Optimization(ORPO)으로 SFT와 DPO를 단일 훈련 과정으로 결합한 것입니다. 이 방법은 두 개의 별도 훈련 루프를 제거해 훈련 과정을 단순화하면서도 QLoRA의 사용을 가능하게 합니다.</p>
</section>
</section>
</section>
<section id="마치며" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> 마치며</h1>
<p>이 글을 통해 우리는 LLM이 어떻게 분류, 생성, 언어 표현을 포함한 특정 작업에 사용할 수 있는지, 그리고 사전 학습된 LLM을 미세 조정하는 다양한 방법을 살펴봤습니다. 이런 기술을 익힘으로써 여러분들은 LLM을 활용해 혁신적인 솔루션을 만들 수 있을 것입니다. 마무리하면서 LLM에 대한 우리의 탐구는 아직 시작에 불과하다는 점을 강조하고 싶습니다. 앞으로 더 많은 흥미로운 발전이 있을 것이며 여러분이 이 분야의 진보를 계속 주시하기를 권장합니다.</p>
</section>
<section id="참고-자료" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> 참고 자료</h1>
<ul>
<li><a href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models">Hands on large language model repo</a></li>
<li><a href="https://github.com/rasbt/LLMs-from-scratch">LLM rfrom scratch</a></li>
<li><a href="https://github.com/philschmid/deep-learning-pytorch-huggingface">Deep learning with pytorch</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/tomorrow-lab\.github\.io\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "partrita/giscus";
    script.dataset.repoId = "R_kgDONvsa2g";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDONvsa2s4CmWd7";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Proudly served by <a href="https://pages.github.com/">github pages</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This blog is built with ❤️ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>